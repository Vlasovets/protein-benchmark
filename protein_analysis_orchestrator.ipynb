{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74cf8003",
   "metadata": {},
   "source": [
    "# Protein Analysis Pipeline Orchestrator\n",
    "\n",
    "This notebook orchestrates the complete protein-based machine learning analysis pipeline, reproducing the R methodology with modular Python components.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This pipeline implements:\n",
    "1. **Data Loading & Validation** - Load protein expression and phenotype data\n",
    "2. **PWAS Analysis** - Protein-Wide Association Study with multiple testing correction\n",
    "3. **Feature Importance** - Random Forest importance ranking\n",
    "4. **Feature Selection** - Recursive Feature Elimination (RFE)\n",
    "5. **Model Training** - Multiple ML models with cross-validation\n",
    "6. **Results Analysis** - Performance metrics and visualization\n",
    "7. **Checkpoint System** - Save/load intermediate results\n",
    "\n",
    "The analysis reproduces the methodology from:\n",
    "`/home/itg/oleg.vlasovets/projects/protein-benchmark/archive/R_analysis/2_train_agnostic_with_checkpoints.Rmd`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296edeee",
   "metadata": {},
   "source": [
    "### Activate conda env protein-benchmark and run jupyter inside of that env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03dfd1",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries and Modules\n",
    "\n",
    "Import necessary Python libraries and custom pipeline modules for each analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a632eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Warning: imbalanced-learn not installed. ROSE sampling will not be available.\n",
      "   Install with: pip install imbalanced-learn\n",
      "‚úÖ Successfully imported all pipeline modules\n",
      "üìÖ Notebook started at: 2025-10-17 20:30:26.376392\n",
      "üíª System info: {'platform': 'Linux-5.14.0-570.25.1.el9_6.x86_64-x86_64-with-glibc2.34', 'python_version': '3.10.19', 'cpu_count': 32, 'memory_total': '754.0 GB', 'memory_available': '660.0 GB'}\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import custom pipeline modules\n",
    "sys.path.append('/home/itg/oleg.vlasovets/projects/protein-benchmark')\n",
    "\n",
    "try:\n",
    "    from pipeline import (\n",
    "        DataLoader, PWASAnalyzer, FeatureImportanceAnalyzer,\n",
    "        FeatureSelector, ModelTrainer, CheckpointSystem,\n",
    "        validate_data_compatibility, create_results_summary,\n",
    "        print_pipeline_summary, timer, get_system_info\n",
    "    )\n",
    "    print(\"‚úÖ Successfully imported all pipeline modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing pipeline modules: {e}\")\n",
    "    print(\"Make sure the pipeline modules are properly installed\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(f\"üìÖ Notebook started at: {datetime.now()}\")\n",
    "print(f\"üíª System info: {get_system_info() if 'get_system_info' in globals() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c899e1",
   "metadata": {},
   "source": [
    "## Section 2: Load and Validate Configuration\n",
    "\n",
    "Set up configuration parameters and validate input paths, model parameters, and checkpoint settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5fae2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e879f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run\n",
      "üìÅ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "üìÅ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/plots\n",
      "üìÅ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports\n",
      "\n",
      "üìã Validating input files...\n",
      "‚úÖ protein_train: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_train.csv (109.4 MB)\n",
      "‚úÖ phenotype_train: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_train.csv (0.3 MB)\n",
      "‚úÖ protein_val: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_val.csv (12.1 MB)\n",
      "‚úÖ phenotype_val: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_val.csv (0.0 MB)\n",
      "\n",
      "üéØ Target variable: oa_status\n",
      "üß¨ Prediction mode: prot_only\n",
      "üé≤ Random seed: 42\n",
      "üìä Cross-validation folds: 10\n",
      "ü§ñ Models to compare: random_forest, logistic_regression, xgboost\n",
      "üíæ Results will be saved to: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    # Data paths (updated to use raw UKBB data files from R analysis)\n",
    "    'data_paths': {\n",
    "        'protein_train': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_train.csv',\n",
    "        'phenotype_train': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_train.csv',\n",
    "        'protein_val': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_val.csv',\n",
    "        'phenotype_val': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_val.csv'\n",
    "    },\n",
    "    \n",
    "    # Analysis parameters\n",
    "    'analysis_params': {\n",
    "        'target_column': 'oa_status',\n",
    "        'pred_mode': 'prot_only',  # 'prot_only', 'sexagebmi', 'comb'\n",
    "        'random_state': 42,\n",
    "        'cv_folds': 10\n",
    "    },\n",
    "    \n",
    "    # PWAS parameters  \n",
    "    'pwas_params': {\n",
    "        'fdr_threshold': 0.05,\n",
    "        'p_threshold': 0.05,\n",
    "        'max_proteins': 200\n",
    "    },\n",
    "    \n",
    "    # Feature selection parameters\n",
    "    'feature_params': {\n",
    "        'rf_n_estimators': 500,\n",
    "        'rfe_n_features': 20,\n",
    "        'rfe_step': 1,\n",
    "        'use_rfe_cv': True\n",
    "    },\n",
    "    \n",
    "    # Model parameters\n",
    "    'model_params': {\n",
    "        'hyperparameter_tuning': False,\n",
    "        'scale_features': False,\n",
    "        'model_types': ['random_forest', 'logistic_regression', 'xgboost'] \n",
    "    },\n",
    "    \n",
    "    # Output paths\n",
    "    'output_paths': {\n",
    "        'base_dir': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run',\n",
    "        'checkpoints': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints',\n",
    "        'plots': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/plots',\n",
    "        'reports': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "for path_key, path_value in CONFIG['output_paths'].items():\n",
    "    Path(path_value).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"üìÅ Created directory: {path_value}\")\n",
    "\n",
    "# Validate input files exist\n",
    "print(\"\\nüìã Validating input files...\")\n",
    "for file_key, file_path in CONFIG['data_paths'].items():\n",
    "    if Path(file_path).exists():\n",
    "        file_size = Path(file_path).stat().st_size / (1024**2)  # MB\n",
    "        print(f\"‚úÖ {file_key}: {file_path} ({file_size:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file_key}: {file_path} (NOT FOUND)\")\n",
    "\n",
    "print(f\"\\nüéØ Target variable: {CONFIG['analysis_params']['target_column']}\")\n",
    "print(f\"üß¨ Prediction mode: {CONFIG['analysis_params']['pred_mode']}\")\n",
    "print(f\"üé≤ Random seed: {CONFIG['analysis_params']['random_state']}\")\n",
    "print(f\"üìä Cross-validation folds: {CONFIG['analysis_params']['cv_folds']}\")\n",
    "print(f\"ü§ñ Models to compare: {', '.join(CONFIG['model_params']['model_types'])}\")\n",
    "print(f\"üíæ Results will be saved to: {CONFIG['output_paths']['base_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbd0e7",
   "metadata": {},
   "source": [
    "## Section 3: Data Loading and Preprocessing\n",
    "\n",
    "Load protein benchmark data, perform preprocessing steps, and prepare training/validation datasets using the data processing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1c490b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Checkpoint directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "üì• Loading protein expression and phenotype data...\n",
      "üì• Loading data for prediction mode: prot_only\n",
      "  üìä Loading protein expression matrices...\n",
      "  üìã Loading phenotype data...\n",
      "  ‚ö†Ô∏è  Found 11456 missing values in training phenotypes\n",
      "  ‚ö†Ô∏è  Found 1261 missing values in validation phenotypes\n",
      "\n",
      "üìä DATA LOADING SUMMARY\n",
      "  üéØ Prediction mode: prot_only\n",
      "  üèãÔ∏è  Training: 2963 samples √ó 2131 features\n",
      "  üß™ Validation: 328 samples √ó 2131 features\n",
      "  üìã Target variable: oa_status\n",
      "  üé™ Training target distribution: {0: 2803, 1: 160}\n",
      "  üé™ Validation target distribution: {0: 311, 1: 17}\n",
      "  üß¨ Features: ['A1BG', 'AAMDC', 'AARSD1', 'ABCA2', 'ABHD14B'] ... ['ZFYVE19', 'ZHX2', 'ZNRD2', 'ZNRF4', 'ZP3']\n",
      "\n",
      "üìä Data loaded successfully!\n",
      "üèãÔ∏è  Training: 2963 samples √ó 2131 features\n",
      "üß™ Validation: 328 samples √ó 2131 features\n",
      "üéØ Target distribution (train): {0: 2803, 1: 160}\n",
      "üéØ Target distribution (val): {0: 311, 1: 17}\n",
      "‚úÖ Data validation passed!\n",
      "‚úÖ Checkpoint saved: 01_data_loading\n",
      "   üìÑ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/01_data_loading.pkl\n",
      "   üóÉÔ∏è  DataFrame 'X_train': (2963, 2131) shape\n",
      "   üóÉÔ∏è  DataFrame 'X_val': (328, 2131) shape\n",
      "üíæ Data loading checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize checkpoint system\n",
    "checkpoint_system = CheckpointSystem(CONFIG['output_paths']['checkpoints'])\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoader(CONFIG['output_paths']['base_dir'])\n",
    "\n",
    "print(\"üì• Loading protein expression and phenotype data...\")\n",
    "\n",
    "# Load data matrices\n",
    "data_dict = data_loader.load_matrices(\n",
    "    protein_train_path=CONFIG['data_paths']['protein_train'],\n",
    "    phenotype_train_path=CONFIG['data_paths']['phenotype_train'],\n",
    "    protein_val_path=CONFIG['data_paths']['protein_val'],\n",
    "    phenotype_val_path=CONFIG['data_paths']['phenotype_val'],\n",
    "    pred_mode=CONFIG['analysis_params']['pred_mode'],\n",
    "    target_column=CONFIG['analysis_params']['target_column']\n",
    ")\n",
    "\n",
    "# Extract matrices for easier access\n",
    "X_train = data_dict['p_mtx_traintest']\n",
    "y_train = data_dict['pheno_train_test'][CONFIG['analysis_params']['target_column']]\n",
    "X_val = data_dict['p_mtx_val'] \n",
    "y_val = data_dict['pheno_val'][CONFIG['analysis_params']['target_column']]\n",
    "\n",
    "print(f\"\\nüìä Data loaded successfully!\")\n",
    "print(f\"üèãÔ∏è  Training: {X_train.shape[0]} samples √ó {X_train.shape[1]} features\")\n",
    "print(f\"üß™ Validation: {X_val.shape[0]} samples √ó {X_val.shape[1]} features\")\n",
    "print(f\"üéØ Target distribution (train): {y_train.value_counts().to_dict()}\")\n",
    "print(f\"üéØ Target distribution (val): {y_val.value_counts().to_dict()}\")\n",
    "\n",
    "# Validate data compatibility\n",
    "validation_results = validate_data_compatibility(\n",
    "    X_train, data_dict['pheno_train_test'], \n",
    "    CONFIG['analysis_params']['target_column']\n",
    ")\n",
    "\n",
    "if validation_results['compatible']:\n",
    "    print(\"‚úÖ Data validation passed!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Data validation warnings:\")\n",
    "    for warning in validation_results['warnings']:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "# Save data loading checkpoint\n",
    "checkpoint_data = {\n",
    "    'data_dict': data_dict,\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_val': X_val,\n",
    "    'y_val': y_val,\n",
    "    'validation_results': validation_results\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(checkpoint_data, '01_data_loading', \"Data loading and validation completed\")\n",
    "print(\"üíæ Data loading checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63f5d9",
   "metadata": {},
   "source": [
    "#### TO DO: check missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc465119",
   "metadata": {},
   "source": [
    "## Section 4: PWAS Analysis (Protein-Wide Association Study)\n",
    "\n",
    "Perform PWAS analysis to identify proteins significantly associated with the target variable, implementing the R fallback strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae858475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Starting PWAS analysis...\n",
      "üß¨ Starting PWAS analysis...\n",
      "  üéØ Target: oa_status\n",
      "  üß™ Proteins: 2131\n",
      "  üë• Samples: 2963\n",
      "  üîß Covariates: ['Age_at_recruitment', 'Sex', 'bmi', 'mean_NPX', 'Plate0', 'Plate2', 'Plate3']\n",
      "    üîß Sex encoding: {'Female': np.int64(0), 'Male': np.int64(1)}\n",
      "  üîß Using covariates: ['Age_at_recruitment', 'Sex_encoded', 'bmi', 'mean_NPX', 'Plate0', 'Plate2', 'Plate3']\n",
      "  üìä Covariate matrix shape: (2963, 7)\n",
      "    Age_at_recruitment: min=39.000, max=70.000, has_nan=False\n",
      "    Sex_encoded: min=0.000, max=1.000, has_nan=False\n",
      "    bmi: min=16.159, max=53.370, has_nan=False\n",
      "    mean_NPX: min=-0.697, max=0.969, has_nan=False\n",
      "    Plate0: min=890000000001.000, max=890000000672.000, has_nan=False\n",
      "    Plate2: min=890000000578.000, max=890000000671.000, has_nan=False\n",
      "    Plate3: min=890000000633.000, max=890000000671.000, has_nan=False\n",
      "  üîÑ Testing 2131 proteins...\n",
      "    Processing protein 1/2131\n",
      "    Processing protein 501/2131\n",
      "    Processing protein 1001/2131\n",
      "    Processing protein 1501/2131\n",
      "    Processing protein 2001/2131\n",
      "\n",
      "üß¨ PWAS ANALYSIS SUMMARY\n",
      "  üî¨ Total proteins tested: 2131\n",
      "  ‚úÖ Valid associations: 2131\n",
      "  üéØ FDR significant (< 0.05): 952\n",
      "  üìä Nominal significant (< 0.05): 1105\n",
      "  üèÜ Best p-value: 5.52e-23\n",
      "  ü•á Top protein: ELN (p = 5.52e-23)\n",
      "\n",
      "  üìã Top 10 proteins:\n",
      "     1. ELN             p=5.52e-23 OR=1.000\n",
      "     2. TNFRSF10B       p=7.53e-19 OR=1.000\n",
      "     3. ADM             p=2.44e-18 OR=1.000\n",
      "     4. TREM2           p=1.21e-17 OR=1.000\n",
      "     5. IGFBP4          p=8.05e-16 OR=1.000\n",
      "     6. CXCL17          p=1.06e-15 OR=1.000\n",
      "     7. FUT3_FUT5       p=5.59e-15 OR=1.000\n",
      "     8. GFRA1           p=1.06e-14 OR=1.000\n",
      "     9. LAMP3           p=1.23e-14 OR=1.000\n",
      "    10. CLMP            p=3.66e-14 OR=1.000\n",
      "\n",
      "üéØ Applying R fallback strategy for protein selection:\n",
      "üéØ Selected 952 FDR-significant proteins\n",
      "  ‚úÇÔ∏è  Limiting to top 200 proteins\n",
      "\n",
      "‚úÖ Selected 200 proteins for analysis\n",
      "üèÜ Top 10 selected proteins:\n",
      "   1. ELN (p = 5.52e-23) ***\n",
      "   2. TNFRSF10B (p = 7.53e-19) ***\n",
      "   3. ADM (p = 2.44e-18) ***\n",
      "   4. TREM2 (p = 1.21e-17) ***\n",
      "   5. IGFBP4 (p = 8.05e-16) ***\n",
      "   6. CXCL17 (p = 1.06e-15) ***\n",
      "   7. FUT3_FUT5 (p = 5.59e-15) ***\n",
      "   8. GFRA1 (p = 1.06e-14) ***\n",
      "   9. LAMP3 (p = 1.23e-14) ***\n",
      "  10. CLMP (p = 3.66e-14) ***\n",
      "\n",
      "üìä Selected feature matrices:\n",
      "üèãÔ∏è  Training: 2963 samples √ó 200 features\n",
      "üß™ Validation: 328 samples √ó 200 features\n",
      "‚úÖ Checkpoint saved: 02_pwas_analysis\n",
      "   üìÑ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/02_pwas_analysis.pkl\n",
      "   üóÉÔ∏è  DataFrame 'X_train_selected': (2963, 200) shape\n",
      "   üóÉÔ∏è  DataFrame 'X_val_selected': (328, 200) shape\n",
      "üíæ PWAS analysis checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize PWAS analyzer\n",
    "pwas_analyzer = PWASAnalyzer()\n",
    "\n",
    "print(\"üß¨ Starting PWAS analysis...\")\n",
    "\n",
    "# Perform PWAS analysis with corrected implementation\n",
    "pwas_results = pwas_analyzer.perform_pwas(\n",
    "    protein_matrix=X_train,\n",
    "    phenotype_data=data_dict['pheno_train_test'],\n",
    "    target_column=CONFIG['analysis_params']['target_column'],\n",
    "    fdr_threshold=CONFIG['pwas_params']['fdr_threshold'],\n",
    "    p_threshold=CONFIG['pwas_params']['p_threshold']\n",
    ")\n",
    "\n",
    "# Check if we got valid results\n",
    "if len(pwas_results['results']) == 0:\n",
    "    print(\"‚ö†Ô∏è No PWAS results obtained. This may be due to:\")\n",
    "    print(\"  - Categorical variable encoding issues\")\n",
    "    print(\"  - Insufficient sample size\") \n",
    "    print(\"  - Data quality issues\")\n",
    "    print(\"\\nUsing all proteins for downstream analysis...\")\n",
    "    \n",
    "    # Fallback: use all proteins\n",
    "    selected_proteins = X_train.columns.tolist()[:CONFIG['pwas_params']['max_proteins']]\n",
    "    print(f\"üìä Selected {len(selected_proteins)} proteins (all available, limited by max_proteins)\")\n",
    "    \n",
    "else:\n",
    "    # Implement R fallback strategy for protein selection\n",
    "    print(\"\\nüéØ Applying R fallback strategy for protein selection:\")\n",
    "\n",
    "    # Strategy 1: Try FDR-significant proteins\n",
    "    selected_proteins = pwas_analyzer.get_selected_proteins(\n",
    "        selection_strategy=\"fdr_significant\",\n",
    "        max_proteins=CONFIG['pwas_params']['max_proteins']\n",
    "    )\n",
    "\n",
    "    if len(selected_proteins) == 0:\n",
    "        print(\"  üìâ No FDR-significant proteins found. Trying nominal significance...\")\n",
    "        # Strategy 2: Try nominally significant proteins\n",
    "        selected_proteins = pwas_analyzer.get_selected_proteins(\n",
    "            selection_strategy=\"nominal_significant\", \n",
    "            max_proteins=CONFIG['pwas_params']['max_proteins']\n",
    "        )\n",
    "\n",
    "    if len(selected_proteins) == 0:\n",
    "        print(\"  üìâ No nominally significant proteins found. Using top proteins by p-value...\")\n",
    "        # Strategy 3: Use top proteins by p-value\n",
    "        selected_proteins = pwas_analyzer.get_selected_proteins(\n",
    "            selection_strategy=\"top_n\",\n",
    "            max_proteins=CONFIG['pwas_params']['max_proteins']\n",
    "        )\n",
    "\n",
    "    print(f\"\\n‚úÖ Selected {len(selected_proteins)} proteins for analysis\")\n",
    "    print(f\"üèÜ Top 10 selected proteins:\")\n",
    "    for i, protein in enumerate(selected_proteins[:10], 1):\n",
    "        # Get p-value for this protein\n",
    "        results_df = pwas_results['results']\n",
    "        protein_row = results_df[results_df['protein'] == protein]\n",
    "        if len(protein_row) > 0:\n",
    "            p_val = protein_row['p_value'].iloc[0]\n",
    "            fdr_sig = \"***\" if protein_row['fdr_significant'].iloc[0] else \"\"\n",
    "            nom_sig = \"**\" if protein_row['nominal_significant'].iloc[0] else \"\"\n",
    "            sig_marker = fdr_sig or nom_sig\n",
    "            print(f\"  {i:2d}. {protein} (p = {p_val:.2e}) {sig_marker}\")\n",
    "\n",
    "# Create feature matrix with selected proteins\n",
    "X_train_selected = X_train[selected_proteins].copy()\n",
    "X_val_selected = X_val[selected_proteins].copy()\n",
    "\n",
    "print(f\"\\nüìä Selected feature matrices:\")\n",
    "print(f\"üèãÔ∏è  Training: {X_train_selected.shape[0]} samples √ó {X_train_selected.shape[1]} features\")\n",
    "print(f\"üß™ Validation: {X_val_selected.shape[0]} samples √ó {X_val_selected.shape[1]} features\")\n",
    "\n",
    "# Save PWAS checkpoint\n",
    "pwas_checkpoint = {\n",
    "    'pwas_results': pwas_results,\n",
    "    'selected_proteins': selected_proteins,\n",
    "    'X_train_selected': X_train_selected,\n",
    "    'X_val_selected': X_val_selected\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(pwas_checkpoint, '02_pwas_analysis', \"PWAS analysis and protein selection completed\")\n",
    "print(\"üíæ PWAS analysis checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40644d46",
   "metadata": {},
   "source": [
    "## Section 5: Feature Importance Analysis\n",
    "\n",
    "Analyze feature importance using Random Forest to rank the selected proteins by their predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72197ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤ Starting Random Forest feature importance analysis...\n",
      "üå≤ Starting Random Forest feature importance analysis...\n",
      "  üìä Features: 200\n",
      "  üë• Samples: 2963\n",
      "  üå≥ Trees: 500\n",
      "  üîÑ Training Random Forest...\n",
      "  üìà Evaluating model performance...\n",
      "\n",
      "üå≤ RANDOM FOREST IMPORTANCE SUMMARY\n",
      "  üéØ Training AUC: 1.0000\n",
      "  üìä CV AUC: 0.8118 ¬± 0.0519\n",
      "  üé≤ OOB Score: 0.9457\n",
      "\n",
      "  üèÜ Top 10 most important features:\n",
      "     1. TREM2                0.0206\n",
      "     2. ADM                  0.0196\n",
      "     3. BGLAP                0.0173\n",
      "     4. ELN                  0.0165\n",
      "     5. CA6                  0.0131\n",
      "     6. TNFRSF10B            0.0121\n",
      "     7. GDF15                0.0115\n",
      "     8. PGF                  0.0113\n",
      "     9. CCL23                0.0112\n",
      "    10. SIGLEC8              0.0107\n",
      "\n",
      "  üìà Importance distribution:\n",
      "    Mean: 0.0050\n",
      "    Std:  0.0030\n",
      "    Max:  0.0206\n",
      "    Min:  0.0017\n",
      "üéØ Selected top 20 features by importance\n",
      "\n",
      "üèÜ Top 20 features by RF importance:\n",
      "   1. TREM2                0.0206\n",
      "   2. ADM                  0.0196\n",
      "   3. BGLAP                0.0173\n",
      "   4. ELN                  0.0165\n",
      "   5. CA6                  0.0131\n",
      "   6. TNFRSF10B            0.0121\n",
      "   7. GDF15                0.0115\n",
      "   8. PGF                  0.0113\n",
      "   9. CCL23                0.0112\n",
      "  10. SIGLEC8              0.0107\n",
      "  11. DNER                 0.0106\n",
      "  12. AMY1A_AMY1B_AMY1C    0.0104\n",
      "  13. COL9A1               0.0103\n",
      "  14. CXCL17               0.0103\n",
      "  15. RGMA                 0.0097\n",
      "  16. LPO                  0.0097\n",
      "  17. CXCL14               0.0094\n",
      "  18. AMY2A                0.0092\n",
      "  19. EDA2R                0.0088\n",
      "  20. GFRA1                0.0088\n",
      "\n",
      "üìä Feature Importance Distribution:\n",
      "\n",
      "üìä Top 20 Feature Importances:\n",
      "  ============================================================\n",
      "   1. TREM2           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 0.0206\n",
      "   2. ADM             |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë| 0.0196\n",
      "   3. BGLAP           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0173\n",
      "   4. ELN             |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0165\n",
      "   5. CA6             |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0131\n",
      "   6. TNFRSF10B       |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0121\n",
      "   7. GDF15           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0115\n",
      "   8. PGF             |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0113\n",
      "   9. CCL23           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0112\n",
      "  10. SIGLEC8         |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0107\n",
      "  11. DNER            |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0106\n",
      "  12. AMY1A_AMY1B_AMY1C |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0104\n",
      "  13. COL9A1          |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0103\n",
      "  14. CXCL17          |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0103\n",
      "  15. RGMA            |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0097\n",
      "  16. LPO             |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0097\n",
      "  17. CXCL14          |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0094\n",
      "  18. AMY2A           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0092\n",
      "  19. EDA2R           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0088\n",
      "  20. GFRA1           |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë| 0.0088\n",
      "‚úÖ Checkpoint saved: 03_feature_importance\n",
      "   üìÑ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/03_feature_importance.pkl\n",
      "üíæ Feature importance checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature importance analyzer\n",
    "importance_analyzer = FeatureImportanceAnalyzer(\n",
    "    random_state=CONFIG['analysis_params']['random_state']\n",
    ")\n",
    "\n",
    "print(\"üå≤ Starting Random Forest feature importance analysis...\")\n",
    "\n",
    "# Analyze feature importance\n",
    "importance_results = importance_analyzer.analyze_rf_importance(\n",
    "    X_train=X_train_selected,\n",
    "    y_train=y_train,\n",
    "    n_estimators=CONFIG['feature_params']['rf_n_estimators'],\n",
    "    cv_folds=CONFIG['analysis_params']['cv_folds']\n",
    ")\n",
    "\n",
    "# Get top features by importance\n",
    "top_features_importance = importance_analyzer.get_top_features(\n",
    "    n_features=CONFIG['feature_params']['rfe_n_features'],\n",
    "    method='top_n'\n",
    ")\n",
    "\n",
    "print(f\"\\nüèÜ Top {len(top_features_importance)} features by RF importance:\")\n",
    "importance_df = importance_results['feature_importance']\n",
    "for i, row in importance_df.head(CONFIG['feature_params']['rfe_n_features']).iterrows():\n",
    "    print(f\"  {i+1:2d}. {row['feature']:20s} {row['importance']:.4f}\")\n",
    "\n",
    "# Visualize feature importance (text-based)\n",
    "print(f\"\\nüìä Feature Importance Distribution:\")\n",
    "importance_analyzer._print_text_importance_plot(20)\n",
    "\n",
    "# Save importance checkpoint - FIX THE PARAMETER ORDER\n",
    "importance_checkpoint = {\n",
    "    'importance_results': importance_results,\n",
    "    'top_features_importance': top_features_importance\n",
    "}\n",
    "\n",
    "# Correct parameter order: data, step_name, description\n",
    "checkpoint_system.save_checkpoint(\n",
    "    importance_checkpoint, \n",
    "    '03_feature_importance', \n",
    "    \"Feature importance analysis completed\"\n",
    ")\n",
    "print(\"üíæ Feature importance checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccba0b",
   "metadata": {},
   "source": [
    "## Section 6: Recursive Feature Elimination (RFE)\n",
    "\n",
    "Perform RFE to systematically select the most predictive features, reducing dimensionality while maintaining performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7275a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Starting Recursive Feature Elimination...\n",
      "üîß Starting Recursive Feature Elimination...\n",
      "  üìä Initial features: 200\n",
      "  üéØ Target features: auto (CV)\n",
      "  üèóÔ∏è  Estimator: random_forest\n",
      "  üîÑ Running RFECV with 10-fold CV...\n",
      "  üìà Evaluating feature selection performance...\n",
      "\n",
      "üîß RFE FEATURE SELECTION SUMMARY\n",
      "  üìä Features selected: 126/200\n",
      "  üéØ Selection ratio: 63.00%\n",
      "  üèóÔ∏è  Estimator: random_forest\n",
      "\n",
      "  üìà Performance with selected features:\n",
      "    Training AUC: 1.0000\n",
      "    CV AUC: 0.8178 ¬± 0.0522\n",
      "\n",
      "  üèÜ Selected features:\n",
      "     1. ELN\n",
      "     2. TNFRSF10B\n",
      "     3. ADM\n",
      "     4. TREM2\n",
      "     5. IGFBP4\n",
      "     6. CXCL17\n",
      "     7. FUT3_FUT5\n",
      "     8. GFRA1\n",
      "     9. LAMP3\n",
      "    10. PGF\n",
      "    ... and 116 more\n",
      "\n",
      "  üìä RFECV Results:\n",
      "    Optimal features: 126\n",
      "    Best CV score: No scores available\n",
      "\n",
      "üéØ RFE selected 126 features:\n",
      "   1. ELN\n",
      "   2. TNFRSF10B\n",
      "   3. ADM\n",
      "   4. TREM2\n",
      "   5. IGFBP4\n",
      "   6. CXCL17\n",
      "   7. FUT3_FUT5\n",
      "   8. GFRA1\n",
      "   9. LAMP3\n",
      "  10. PGF\n",
      "  11. LECT2\n",
      "  12. COL9A1\n",
      "  13. EDA2R\n",
      "  14. GDF15\n",
      "  15. CCN3\n",
      "  16. DNER\n",
      "  17. FSTL3\n",
      "  18. PIK3IP1\n",
      "  19. COL18A1\n",
      "  20. CD302\n",
      "  21. CXCL14\n",
      "  22. COL6A3\n",
      "  23. CA6\n",
      "  24. SIGLEC8\n",
      "  25. CD276\n",
      "  26. LGALS9\n",
      "  27. CD300LF\n",
      "  28. GALNT10\n",
      "  29. CXCL9\n",
      "  30. TNFRSF9\n",
      "  31. PRG2\n",
      "  32. EFNA1\n",
      "  33. CD300A\n",
      "  34. CCL23\n",
      "  35. CD99L2\n",
      "  36. PLAUR\n",
      "  37. RBFOX3\n",
      "  38. SCARF2\n",
      "  39. ACTA2\n",
      "  40. LPO\n",
      "  41. CKB\n",
      "  42. SHISA5\n",
      "  43. LILRB4\n",
      "  44. AMBP\n",
      "  45. HLA.E\n",
      "  46. TNFRSF12A\n",
      "  47. IGFBPL1\n",
      "  48. RARRES2\n",
      "  49. ULBP2\n",
      "  50. CDCP1\n",
      "  51. PROK1\n",
      "  52. CLEC4D\n",
      "  53. RNF149\n",
      "  54. CEACAM1\n",
      "  55. WNT9A\n",
      "  56. CCL27\n",
      "  57. AMY2A\n",
      "  58. CHIT1\n",
      "  59. LRRN1\n",
      "  60. FBLN2\n",
      "  61. ADIPOQ\n",
      "  62. CPPED1\n",
      "  63. AMY2B\n",
      "  64. MMP12\n",
      "  65. ADAM9\n",
      "  66. BOC\n",
      "  67. TFF3\n",
      "  68. BGLAP\n",
      "  69. LTA4H\n",
      "  70. HAVCR1\n",
      "  71. PALM2\n",
      "  72. HSPB6\n",
      "  73. CAPS\n",
      "  74. KLK7\n",
      "  75. ADAMTS16\n",
      "  76. PPCDC\n",
      "  77. MERTK\n",
      "  78. ENPP5\n",
      "  79. AMY1A_AMY1B_AMY1C\n",
      "  80. PRG3\n",
      "  81. TNFSF13\n",
      "  82. TXNRD1\n",
      "  83. MLN\n",
      "  84. RGMA\n",
      "  85. MSTN\n",
      "  86. BCAN\n",
      "  87. CCN1\n",
      "  88. CA14\n",
      "  89. CLEC6A\n",
      "  90. TXNDC15\n",
      "  91. NCAN\n",
      "  92. PRSS8\n",
      "  93. SEPTIN8\n",
      "  94. CD80\n",
      "  95. PLA2G15\n",
      "  96. XG\n",
      "  97. TNFSF13B\n",
      "  98. ICAM5\n",
      "  99. SORCS2\n",
      "  100. FABP4\n",
      "  101. NTproBNP\n",
      "  102. SFTPD\n",
      "  103. GIP\n",
      "  104. RSPO3\n",
      "  105. TNFRSF14\n",
      "  106. SUSD2\n",
      "  107. RRM2B\n",
      "  108. CXCL1\n",
      "  109. ANGPTL4\n",
      "  110. VSIG4\n",
      "  111. EFHD1\n",
      "  112. STX6\n",
      "  113. NT5C1A\n",
      "  114. CTSO\n",
      "  115. RSPO1\n",
      "  116. SLC39A5\n",
      "  117. CAPG\n",
      "  118. CEACAM5\n",
      "  119. PTN\n",
      "  120. MSLN\n",
      "  121. DPP10\n",
      "  122. CPM\n",
      "  123. F7\n",
      "  124. PHOSPHO1\n",
      "  125. HNMT\n",
      "  126. FCRL5\n",
      "\n",
      "üìä Final feature matrices after RFE:\n",
      "üèãÔ∏è  Training: 2963 samples √ó 126 features\n",
      "üß™ Validation: 328 samples √ó 126 features\n",
      "\n",
      "üìâ Feature reduction summary:\n",
      "  Original features: 2,131\n",
      "  After PWAS: 200\n",
      "  After RFE: 126\n",
      "  Total reduction: 94.1%\n",
      "‚úÖ Checkpoint saved: 04_feature_selection\n",
      "   üìÑ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/04_feature_selection.pkl\n",
      "   üóÉÔ∏è  DataFrame 'X_train_final': (2963, 126) shape\n",
      "   üóÉÔ∏è  DataFrame 'X_val_final': (328, 126) shape\n",
      "üíæ Feature selection checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature selector\n",
    "feature_selector = FeatureSelector(\n",
    "    random_state=CONFIG['analysis_params']['random_state']\n",
    ")\n",
    "\n",
    "print(\"üîß Starting Recursive Feature Elimination...\")\n",
    "\n",
    "# Run RFE with cross-validation\n",
    "rfe_results = feature_selector.run_rfe(\n",
    "    X_train=X_train_selected,\n",
    "    y_train=y_train,\n",
    "    estimator_type='random_forest',\n",
    "    n_features_to_select=CONFIG['feature_params']['rfe_n_features'] if not CONFIG['feature_params']['use_rfe_cv'] else None,\n",
    "    step=CONFIG['feature_params']['rfe_step'],\n",
    "    cv_folds=CONFIG['analysis_params']['cv_folds'],\n",
    "    use_cv=CONFIG['feature_params']['use_rfe_cv']\n",
    ")\n",
    "\n",
    "# Get selected features from RFE\n",
    "selected_features_rfe = feature_selector.get_selected_features()\n",
    "\n",
    "print(f\"\\nüéØ RFE selected {len(selected_features_rfe)} features:\")\n",
    "for i, feature in enumerate(selected_features_rfe, 1):\n",
    "    print(f\"  {i:2d}. {feature}\")\n",
    "\n",
    "# Create final feature matrices\n",
    "X_train_final = feature_selector.transform_features(X_train_selected)\n",
    "X_val_final = feature_selector.transform_features(X_val_selected)\n",
    "\n",
    "print(f\"\\nüìä Final feature matrices after RFE:\")\n",
    "print(f\"üèãÔ∏è  Training: {X_train_final.shape[0]} samples √ó {X_train_final.shape[1]} features\")\n",
    "print(f\"üß™ Validation: {X_val_final.shape[0]} samples √ó {X_val_final.shape[1]} features\")\n",
    "\n",
    "# Print feature reduction summary\n",
    "print(f\"\\nüìâ Feature reduction summary:\")\n",
    "print(f\"  Original features: {X_train.shape[1]:,}\")\n",
    "print(f\"  After PWAS: {X_train_selected.shape[1]:,}\")\n",
    "print(f\"  After RFE: {X_train_final.shape[1]:,}\")\n",
    "print(f\"  Total reduction: {(1 - X_train_final.shape[1]/X_train.shape[1]):.1%}\")\n",
    "\n",
    "# Save RFE checkpoint\n",
    "rfe_checkpoint = {\n",
    "    'rfe_results': rfe_results,\n",
    "    'selected_features_rfe': selected_features_rfe,\n",
    "    'X_train_final': X_train_final,\n",
    "    'X_val_final': X_val_final\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(\n",
    "    rfe_checkpoint, \n",
    "    '04_feature_selection', \n",
    "    \"Feature selection and RFE completed\"\n",
    ")\n",
    "print(\"üíæ Feature selection checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7394ae3",
   "metadata": {},
   "source": [
    "## Section 7: Model Training and Evaluation\n",
    "\n",
    "Train multiple machine learning models using the selected features and evaluate their performance with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a8415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Starting model training and evaluation...\n",
      "üìã Models to compare: ['random_forest', 'logistic_regression', 'xgboost']\n",
      "üèÜ Comparing 3 models...\n",
      "\n",
      "  ü§ñ Training random_forest...\n",
      "ü§ñ Training random_forest model...\n",
      "  üìä Training: 2963 samples √ó 126 features\n",
      "  üß™ Validation: 328 samples\n",
      "  üîÑ Training model...\n",
      "  üìà Evaluating performance...\n",
      "\n",
      "ü§ñ MODEL TRAINING SUMMARY: RANDOM_FOREST\n",
      "  üìä Features: 126\n",
      "  üë• Training samples: 2963\n",
      "  üß™ Validation samples: 328\n",
      "  üéØ Training AUC: 1.0000\n",
      "  üéØ Training Accuracy: 1.0000\n",
      "  üìä CV AUC: 0.8255 ¬± 0.0525\n",
      "  üß™ Validation AUC: 0.7785\n",
      "  üß™ Validation Accuracy: 0.9482\n",
      "  üé≤ OOB Score: 0.9457\n",
      "\n",
      "  ü§ñ Training logistic_regression...\n",
      "ü§ñ Training logistic_regression model...\n",
      "  üìä Training: 2963 samples √ó 126 features\n",
      "  üß™ Validation: 328 samples\n",
      "  üîÑ Training model...\n",
      "  üìà Evaluating performance...\n",
      "\n",
      "ü§ñ MODEL TRAINING SUMMARY: LOGISTIC_REGRESSION\n",
      "  üìä Features: 126\n",
      "  üë• Training samples: 2963\n",
      "  üß™ Validation samples: 328\n",
      "  üéØ Training AUC: 0.9168\n",
      "  üéØ Training Accuracy: 0.8252\n",
      "  üìä CV AUC: 0.7969 ¬± 0.0295\n",
      "  üß™ Validation AUC: 0.7344\n",
      "  üß™ Validation Accuracy: 0.7622\n",
      "\n",
      "  ü§ñ Training xgboost...\n",
      "ü§ñ Training xgboost model...\n",
      "  üìä Training: 2963 samples √ó 126 features\n",
      "  üß™ Validation: 328 samples\n",
      "  üîÑ Training model...\n",
      "  üìà Evaluating performance...\n",
      "\n",
      "ü§ñ MODEL TRAINING SUMMARY: XGBOOST\n",
      "  üìä Features: 126\n",
      "  üë• Training samples: 2963\n",
      "  üß™ Validation samples: 328\n",
      "  üéØ Training AUC: 1.0000\n",
      "  üéØ Training Accuracy: 1.0000\n",
      "  üìä CV AUC: 0.8465 ¬± 0.0384\n",
      "  üß™ Validation AUC: 0.7594\n",
      "  üß™ Validation Accuracy: 0.9451\n",
      "\n",
      "üèÜ MODEL COMPARISON SUMMARY\n",
      "  ================================================================================\n",
      "  Model                Train AUC    CV AUC       Val AUC     \n",
      "  ------------------------------------------------------------\n",
      "  random_forest        1.0000       0.8255       0.7785      \n",
      "  logistic_regression  0.9168       0.7969       0.7344      \n",
      "  xgboost              1.0000       0.8465       0.7594      \n",
      "\n",
      "üèÜ Model Comparison Results:\n",
      "================================================================================\n",
      "\n",
      "üå≤ RANDOM FOREST\n",
      "  üéØ Training AUC:   1.0000\n",
      "  üìä CV AUC:        0.8255\n",
      "  üß™ Validation AUC: 0.7785\n",
      "\n",
      "üìà LOGISTIC REGRESSION\n",
      "  üéØ Training AUC:   0.9168\n",
      "  üìä CV AUC:        0.7969\n",
      "  üß™ Validation AUC: 0.7344\n",
      "\n",
      "üöÄ XGBOOST\n",
      "  üéØ Training AUC:   1.0000\n",
      "  üìä CV AUC:        0.8465\n",
      "  üß™ Validation AUC: 0.7594\n",
      "\n",
      "ü•á Best model: Xgboost (CV AUC: 0.8465)\n",
      "\n",
      "üìä Final validation metrics (Xgboost):\n",
      "  ACCURACY: 0.9451\n",
      "  PRECISION: 0.0000\n",
      "  RECALL: 0.0000\n",
      "  F1_SCORE: 0.0000\n",
      "  AUC: 0.7594\n",
      "\n",
      "Differences from R Pipeline:\n",
      "  üìä CV AUC: -0.1427\n",
      "  üß™ Validation AUC: +0.1073\n",
      "‚úÖ Python pipeline has better validation performance\n",
      "‚úÖ Checkpoint saved: 05_model_training\n",
      "   üìÑ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/05_model_training.pkl\n",
      "üíæ Model training checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize model trainer\n",
    "model_trainer = ModelTrainer(\n",
    "    random_state=CONFIG['analysis_params']['random_state']\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Starting model training and evaluation...\")\n",
    "print(f\"üìã Models to compare: {CONFIG['model_params']['model_types']}\")\n",
    "\n",
    "# Compare multiple models (now including XGBoost)\n",
    "model_comparison = model_trainer.compare_models(\n",
    "    X_train=X_train_final,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_final,\n",
    "    y_val=y_val,\n",
    "    model_types=CONFIG['model_params']['model_types'],\n",
    "    cv_folds=CONFIG['analysis_params']['cv_folds']\n",
    ")\n",
    "\n",
    "print(\"\\nüèÜ Model Comparison Results:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model_type = None\n",
    "best_cv_auc = 0\n",
    "\n",
    "for model_type, results in model_comparison.items():\n",
    "    performance = results['performance']\n",
    "    \n",
    "    # Extract key metrics\n",
    "    train_auc = performance.get('train', {}).get('auc', 'N/A')\n",
    "    cv_auc = performance.get('cross_validation', {}).get('auc_mean', 'N/A')\n",
    "    val_auc = performance.get('validation', {}).get('auc', 'N/A')\n",
    "    \n",
    "    # Add emoji for model type\n",
    "    model_emoji = {\n",
    "        'random_forest': 'üå≤',\n",
    "        'logistic_regression': 'üìà', \n",
    "        'xgboost': 'üöÄ'\n",
    "    }.get(model_type, 'ü§ñ')\n",
    "    \n",
    "    print(f\"\\n{model_emoji} {model_type.upper().replace('_', ' ')}\")\n",
    "    print(f\"  üéØ Training AUC:   {train_auc:.4f}\" if isinstance(train_auc, (int, float)) else f\"  üéØ Training AUC:   {train_auc}\")\n",
    "    print(f\"  üìä CV AUC:        {cv_auc:.4f}\" if isinstance(cv_auc, (int, float)) else f\"  üìä CV AUC:        {cv_auc}\")\n",
    "    print(f\"  üß™ Validation AUC: {val_auc:.4f}\" if isinstance(val_auc, (int, float)) else f\"  üß™ Validation AUC: {val_auc}\")\n",
    "    \n",
    "    # Track best model by CV AUC\n",
    "    if isinstance(cv_auc, (int, float)) and cv_auc > best_cv_auc:\n",
    "        best_cv_auc = cv_auc\n",
    "        best_model_type = model_type\n",
    "\n",
    "print(f\"\\nü•á Best model: {best_model_type.replace('_', ' ').title()} (CV AUC: {best_cv_auc:.4f})\")\n",
    "\n",
    "\n",
    "# Train the best model with hyperparameter tuning if requested\n",
    "if CONFIG['model_params']['hyperparameter_tuning'] and best_model_type:\n",
    "    print(f\"\\nüîß Training {best_model_type.replace('_', ' ').title()} with hyperparameter tuning...\")\n",
    "    \n",
    "    final_model_results = model_trainer.train_model(\n",
    "        X_train=X_train_final,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_final,\n",
    "        y_val=y_val,\n",
    "        model_type=best_model_type,\n",
    "        hyperparameter_tuning=True,\n",
    "        cv_folds=CONFIG['analysis_params']['cv_folds']\n",
    "    )\n",
    "else:\n",
    "    final_model_results = model_comparison[best_model_type] if best_model_type else None\n",
    "\n",
    "# Generate predictions on validation set\n",
    "if best_model_type and final_model_results:\n",
    "    predictions, probabilities = model_trainer.predict(\n",
    "        X_val_final, \n",
    "        model_type=best_model_type,\n",
    "        return_probabilities=True\n",
    "    )\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    final_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, predictions),\n",
    "        'precision': precision_score(y_val, predictions),\n",
    "        'recall': recall_score(y_val, predictions),\n",
    "        'f1_score': f1_score(y_val, predictions),\n",
    "        'auc': roc_auc_score(y_val, probabilities)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìä Final validation metrics ({best_model_type.replace('_', ' ').title()}):\")\n",
    "    for metric, value in final_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # Calculate and display differences from R pipeline\n",
    "    if isinstance(final_metrics['auc'], (int, float)):\n",
    "        cv_diff = best_cv_auc - 0.9892\n",
    "        val_diff = final_metrics['auc'] - 0.6521\n",
    "        \n",
    "        print(f\"\\nDifferences from R Pipeline:\")\n",
    "        print(f\"  üìä CV AUC: {cv_diff:+.4f}\")\n",
    "        print(f\"  üß™ Validation AUC: {val_diff:+.4f}\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        if cv_diff > 0 and val_diff > 0:\n",
    "            print(\"üéâ Python pipeline outperforms R pipeline on both metrics!\")\n",
    "        elif val_diff > 0:\n",
    "            print(\"‚úÖ Python pipeline has better validation performance\")\n",
    "        elif cv_diff > 0:\n",
    "            print(\"‚úÖ Python pipeline has better cross-validation performance\")\n",
    "        else:\n",
    "            print(\"üìù Python pipeline has different performance characteristics\")\n",
    "\n",
    "# Save model training checkpoint\n",
    "model_checkpoint = {\n",
    "    'model_comparison': model_comparison,\n",
    "    'best_model_type': best_model_type,\n",
    "    'final_model_results': final_model_results,\n",
    "    'final_metrics': final_metrics if 'final_metrics' in locals() else None,\n",
    "    'predictions': predictions if 'predictions' in locals() else None,\n",
    "    'probabilities': probabilities if 'probabilities' in locals() else None\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(\n",
    "    model_checkpoint, \n",
    "    '05_model_training', \n",
    "    f\"Model training and evaluation completed with {len(CONFIG['model_params']['model_types'])} models including XGBoost\"\n",
    ")\n",
    "print(\"üíæ Model training checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161f8ce",
   "metadata": {},
   "source": [
    "## Section 8: Results Visualization and Summary\n",
    "\n",
    "Generate plots and comprehensive summary to visualize the pipeline results and compare with original R analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2f6a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Generating comprehensive pipeline results summary...\n",
      "‚úÖ Checkpoint loaded: 01_data_loading\n",
      "   üìÖ Saved: 2025-10-17T20:37:52.076664\n",
      "‚úÖ Checkpoint loaded: 02_pwas_analysis\n",
      "   üìÖ Saved: 2025-10-17T20:38:07.888061\n",
      "‚úÖ Checkpoint loaded: 03_feature_importance\n",
      "   üìÖ Saved: 2025-10-17T20:39:59.376388\n",
      "‚úÖ Checkpoint loaded: 04_feature_selection\n",
      "   üìÖ Saved: 2025-10-17T20:57:57.811384\n",
      "‚úÖ Checkpoint loaded: 05_model_training\n",
      "   üìÖ Saved: 2025-10-17T21:04:57.974893\n",
      "üìä Results summary saved to: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports/pipeline_summary.json\n",
      "\n",
      "================================================================================\n",
      "üß¨ PROTEIN ANALYSIS PIPELINE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üìã PIPELINE OVERVIEW\n",
      "  ‚úÖ Steps completed: 5\n",
      "  üïí Timestamp: 2025-10-17T21:06:15.007180\n",
      "  üîß Steps: data_loading, pwas_analysis, feature_importance, feature_selection, model_training\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìà PERFORMANCE COMPARISON WITH R PIPELINE\n",
      "================================================================================\n",
      "R Pipeline Results (Reference):\n",
      "  üß¨ Proteins selected: 200\n",
      "  üéØ Final features: 8\n",
      "  üìä CV AUC: 0.9892\n",
      "  üß™ Validation AUC: 0.6521\n",
      "\n",
      "Python Pipeline Results (Current):\n",
      "  üß¨ Proteins selected: 200\n",
      "  üéØ Final features: 126\n",
      "  üìä CV AUC: 0.8465\n",
      "  üß™ Validation AUC: 0.7594\n",
      "\n",
      "üß¨ SELECTED FEATURES SUMMARY\n",
      "================================================================================\n",
      "Final selected features (126):\n",
      "   1. ELN                       (importance: 0.0165)\n",
      "   2. TNFRSF10B                 (importance: 0.0121)\n",
      "   3. ADM                       (importance: 0.0196)\n",
      "   4. TREM2                     (importance: 0.0206)\n",
      "   5. IGFBP4                    (importance: 0.0082)\n",
      "   6. CXCL17                    (importance: 0.0103)\n",
      "   7. FUT3_FUT5                 (importance: 0.0081)\n",
      "   8. GFRA1                     (importance: 0.0088)\n",
      "   9. LAMP3                     (importance: 0.0080)\n",
      "  10. PGF                       (importance: 0.0113)\n",
      "  11. LECT2                     (importance: 0.0062)\n",
      "  12. COL9A1                    (importance: 0.0103)\n",
      "  13. EDA2R                     (importance: 0.0088)\n",
      "  14. GDF15                     (importance: 0.0115)\n",
      "  15. CCN3                      (importance: 0.0032)\n",
      "  16. DNER                      (importance: 0.0106)\n",
      "  17. FSTL3                     (importance: 0.0047)\n",
      "  18. PIK3IP1                   (importance: 0.0060)\n",
      "  19. COL18A1                   (importance: 0.0079)\n",
      "  20. CD302                     (importance: 0.0062)\n",
      "  21. CXCL14                    (importance: 0.0094)\n",
      "  22. COL6A3                    (importance: 0.0052)\n",
      "  23. CA6                       (importance: 0.0131)\n",
      "  24. SIGLEC8                   (importance: 0.0107)\n",
      "  25. CD276                     (importance: 0.0075)\n",
      "  26. LGALS9                    (importance: 0.0039)\n",
      "  27. CD300LF                   (importance: 0.0037)\n",
      "  28. GALNT10                   (importance: 0.0082)\n",
      "  29. CXCL9                     (importance: 0.0056)\n",
      "  30. TNFRSF9                   (importance: 0.0047)\n",
      "  31. PRG2                      (importance: 0.0046)\n",
      "  32. EFNA1                     (importance: 0.0057)\n",
      "  33. CD300A                    (importance: 0.0045)\n",
      "  34. CCL23                     (importance: 0.0112)\n",
      "  35. CD99L2                    (importance: 0.0044)\n",
      "  36. PLAUR                     (importance: 0.0033)\n",
      "  37. RBFOX3                    (importance: 0.0044)\n",
      "  38. SCARF2                    (importance: 0.0030)\n",
      "  39. ACTA2                     (importance: 0.0082)\n",
      "  40. LPO                       (importance: 0.0097)\n",
      "  41. CKB                       (importance: 0.0057)\n",
      "  42. SHISA5                    (importance: 0.0051)\n",
      "  43. LILRB4                    (importance: 0.0035)\n",
      "  44. AMBP                      (importance: 0.0043)\n",
      "  45. HLA.E                     (importance: 0.0041)\n",
      "  46. TNFRSF12A                 (importance: 0.0038)\n",
      "  47. IGFBPL1                   (importance: 0.0038)\n",
      "  48. RARRES2                   (importance: 0.0037)\n",
      "  49. ULBP2                     (importance: 0.0036)\n",
      "  50. CDCP1                     (importance: 0.0045)\n",
      "  51. PROK1                     (importance: 0.0084)\n",
      "  52. CLEC4D                    (importance: 0.0045)\n",
      "  53. RNF149                    (importance: 0.0033)\n",
      "  54. CEACAM1                   (importance: 0.0069)\n",
      "  55. WNT9A                     (importance: 0.0049)\n",
      "  56. CCL27                     (importance: 0.0029)\n",
      "  57. AMY2A                     (importance: 0.0092)\n",
      "  58. CHIT1                     (importance: 0.0059)\n",
      "  59. LRRN1                     (importance: 0.0048)\n",
      "  60. FBLN2                     (importance: 0.0047)\n",
      "  61. ADIPOQ                    (importance: 0.0079)\n",
      "  62. CPPED1                    (importance: 0.0066)\n",
      "  63. AMY2B                     (importance: 0.0082)\n",
      "  64. MMP12                     (importance: 0.0059)\n",
      "  65. ADAM9                     (importance: 0.0058)\n",
      "  66. BOC                       (importance: 0.0078)\n",
      "  67. TFF3                      (importance: 0.0048)\n",
      "  68. BGLAP                     (importance: 0.0173)\n",
      "  69. LTA4H                     (importance: 0.0061)\n",
      "  70. HAVCR1                    (importance: 0.0044)\n",
      "  71. PALM2                     (importance: 0.0037)\n",
      "  72. HSPB6                     (importance: 0.0063)\n",
      "  73. CAPS                      (importance: 0.0049)\n",
      "  74. KLK7                      (importance: 0.0083)\n",
      "  75. ADAMTS16                  (importance: 0.0079)\n",
      "  76. PPCDC                     (importance: 0.0034)\n",
      "  77. MERTK                     (importance: 0.0045)\n",
      "  78. ENPP5                     (importance: 0.0050)\n",
      "  79. AMY1A_AMY1B_AMY1C         (importance: 0.0104)\n",
      "  80. PRG3                      (importance: 0.0053)\n",
      "  81. TNFSF13                   (importance: 0.0048)\n",
      "  82. TXNRD1                    (importance: 0.0037)\n",
      "  83. MLN                       (importance: 0.0046)\n",
      "  84. RGMA                      (importance: 0.0097)\n",
      "  85. MSTN                      (importance: 0.0071)\n",
      "  86. BCAN                      (importance: 0.0070)\n",
      "  87. CCN1                      (importance: 0.0061)\n",
      "  88. CA14                      (importance: 0.0076)\n",
      "  89. CLEC6A                    (importance: 0.0038)\n",
      "  90. TXNDC15                   (importance: 0.0041)\n",
      "  91. NCAN                      (importance: 0.0062)\n",
      "  92. PRSS8                     (importance: 0.0039)\n",
      "  93. SEPTIN8                   (importance: 0.0050)\n",
      "  94. CD80                      (importance: 0.0047)\n",
      "  95. PLA2G15                   (importance: 0.0035)\n",
      "  96. XG                        (importance: 0.0037)\n",
      "  97. TNFSF13B                  (importance: 0.0045)\n",
      "  98. ICAM5                     (importance: 0.0036)\n",
      "  99. SORCS2                    (importance: 0.0031)\n",
      "  100. FABP4                     (importance: 0.0049)\n",
      "  101. NTproBNP                  (importance: 0.0045)\n",
      "  102. SFTPD                     (importance: 0.0068)\n",
      "  103. GIP                       (importance: 0.0041)\n",
      "  104. RSPO3                     (importance: 0.0034)\n",
      "  105. TNFRSF14                  (importance: 0.0035)\n",
      "  106. SUSD2                     (importance: 0.0032)\n",
      "  107. RRM2B                     (importance: 0.0037)\n",
      "  108. CXCL1                     (importance: 0.0061)\n",
      "  109. ANGPTL4                   (importance: 0.0032)\n",
      "  110. VSIG4                     (importance: 0.0039)\n",
      "  111. EFHD1                     (importance: 0.0031)\n",
      "  112. STX6                      (importance: 0.0042)\n",
      "  113. NT5C1A                    (importance: 0.0041)\n",
      "  114. CTSO                      (importance: 0.0028)\n",
      "  115. RSPO1                     (importance: 0.0059)\n",
      "  116. SLC39A5                   (importance: 0.0038)\n",
      "  117. CAPG                      (importance: 0.0032)\n",
      "  118. CEACAM5                   (importance: 0.0079)\n",
      "  119. PTN                       (importance: 0.0042)\n",
      "  120. MSLN                      (importance: 0.0042)\n",
      "  121. DPP10                     (importance: 0.0068)\n",
      "  122. CPM                       (importance: 0.0037)\n",
      "  123. F7                        (importance: 0.0028)\n",
      "  124. PHOSPHO1                  (importance: 0.0028)\n",
      "  125. HNMT                      (importance: 0.0034)\n",
      "  126. FCRL5                     (importance: 0.0053)\n",
      "\n",
      "üíæ Results saved to:\n",
      "  üìä JSON summary: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports/pipeline_summary.json\n",
      "  üìù Text summary: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports/pipeline_summary.txt\n",
      "\n",
      "üìä CHECKPOINT SUMMARY - Run ID: unknown\n",
      "============================================================\n",
      "üìÅ Checkpoint directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "üíæ Total checkpoints: 5\n",
      "\n",
      "üìã Step Details:\n",
      "---------------------------------------------------------------------------\n",
      "üì¶ 01_data_loading\n",
      "   üìÖ Time: 2025-10-17T20:37:52.076664\n",
      "   üìù Description: Data loading and validation completed\n",
      "   üíæ Size: 54.0MB\n",
      "‚úÖ Checkpoint loaded: 01_data_loading\n",
      "   üìÖ Saved: 2025-10-17T20:37:52.076664\n",
      "   üìä Data: keys: 6\n",
      "\n",
      "üì¶ 02_pwas_analysis\n",
      "   üìÖ Time: 2025-10-17T20:38:07.888061\n",
      "   üìù Description: PWAS analysis and protein selection completed\n",
      "   üíæ Size: 174.9KB\n",
      "‚úÖ Checkpoint loaded: 02_pwas_analysis\n",
      "   üìÖ Saved: 2025-10-17T20:38:07.888061\n",
      "   üìä Data: keys: 4\n",
      "\n",
      "üì¶ 03_feature_importance\n",
      "   üìÖ Time: 2025-10-17T20:39:59.376388\n",
      "   üìù Description: Feature importance analysis completed\n",
      "   üíæ Size: 4.9KB\n",
      "‚úÖ Checkpoint loaded: 03_feature_importance\n",
      "   üìÖ Saved: 2025-10-17T20:39:59.376388\n",
      "   üìä Data: keys: 2\n",
      "\n",
      "üì¶ 04_feature_selection\n",
      "   üìÖ Time: 2025-10-17T20:57:57.811384\n",
      "   üìù Description: Feature selection and RFE completed\n",
      "   üíæ Size: 3.5MB\n",
      "‚úÖ Checkpoint loaded: 04_feature_selection\n",
      "   üìÖ Saved: 2025-10-17T20:57:57.811384\n",
      "   üìä Data: keys: 4\n",
      "\n",
      "üì¶ 05_model_training\n",
      "   üìÖ Time: 2025-10-17T21:04:57.974893\n",
      "   üìù Description: Model training and evaluation completed with 3 models including XGBoost\n",
      "   üíæ Size: 10.9MB\n",
      "‚úÖ Checkpoint loaded: 05_model_training\n",
      "   üìÖ Saved: 2025-10-17T21:04:57.974893\n",
      "   üìä Data: keys: 6\n",
      "\n",
      "\n",
      "üéâ Pipeline execution completed successfully!\n",
      "‚è±Ô∏è  Total execution time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive results summary\n",
    "print(\"üìä Generating comprehensive pipeline results summary...\")\n",
    "\n",
    "# Collect all results\n",
    "all_results = {\n",
    "    'data_loading': checkpoint_system.load_checkpoint('01_data_loading') if checkpoint_system.checkpoint_exists('01_data_loading') else None,\n",
    "    'pwas_analysis': checkpoint_system.load_checkpoint('02_pwas_analysis') if checkpoint_system.checkpoint_exists('02_pwas_analysis') else None,\n",
    "    'feature_importance': checkpoint_system.load_checkpoint('03_feature_importance') if checkpoint_system.checkpoint_exists('03_feature_importance') else None,\n",
    "    'feature_selection': checkpoint_system.load_checkpoint('04_feature_selection') if checkpoint_system.checkpoint_exists('04_feature_selection') else None,\n",
    "    'model_training': checkpoint_system.load_checkpoint('05_model_training') if checkpoint_system.checkpoint_exists('05_model_training') else None\n",
    "}\n",
    "\n",
    "# Create results summary\n",
    "summary_path = Path(CONFIG['output_paths']['reports']) / 'pipeline_summary.json'\n",
    "pipeline_summary = create_results_summary(\n",
    "    {k: v for k, v in all_results.items() if v is not None},\n",
    "    save_path=str(summary_path)\n",
    ")\n",
    "\n",
    "# Print formatted summary\n",
    "print_pipeline_summary(pipeline_summary)\n",
    "\n",
    "# Generate text-based visualizations\n",
    "print(f\"\\nüìà PERFORMANCE COMPARISON WITH R PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare with known R results (from the exact_pipeline_reproduction.py)\n",
    "r_pipeline_results = {\n",
    "    'proteins_selected': 200,  # Top 200 proteins selected in R\n",
    "    'final_features': 8,      # Final features after RFE in R  \n",
    "    'cv_auc': 0.9892,        # Cross-validation AUC in R\n",
    "    'val_auc': 0.6521        # Validation AUC in R\n",
    "}\n",
    "\n",
    "print(\"R Pipeline Results (Reference):\")\n",
    "print(f\"  üß¨ Proteins selected: {r_pipeline_results['proteins_selected']}\")\n",
    "print(f\"  üéØ Final features: {r_pipeline_results['final_features']}\")\n",
    "print(f\"  üìä CV AUC: {r_pipeline_results['cv_auc']:.4f}\")\n",
    "print(f\"  üß™ Validation AUC: {r_pipeline_results['val_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nPython Pipeline Results (Current):\")\n",
    "print(f\"  üß¨ Proteins selected: {len(selected_proteins) if 'selected_proteins' in globals() else 'N/A'}\")\n",
    "print(f\"  üéØ Final features: {len(selected_features_rfe) if 'selected_features_rfe' in globals() else 'N/A'}\")\n",
    "\n",
    "if 'model_checkpoint' in locals() and model_checkpoint['final_model_results']:\n",
    "    final_perf = model_checkpoint['final_model_results']['performance']\n",
    "    cv_auc_python = final_perf.get('cross_validation', {}).get('auc_mean', 'N/A')\n",
    "    val_auc_python = final_perf.get('validation', {}).get('auc', 'N/A')\n",
    "    \n",
    "    print(f\"  üìä CV AUC: {cv_auc_python:.4f}\" if isinstance(cv_auc_python, (int, float)) else f\"  üìä CV AUC: {cv_auc_python}\")\n",
    "    print(f\"  üß™ Validation AUC: {val_auc_python:.4f}\" if isinstance(val_auc_python, (int, float)) else f\"  üß™ Validation AUC: {val_auc_python}\")\n",
    "\n",
    "# Create feature importance visualization (text-based)\n",
    "if 'importance_results' in locals():\n",
    "    print(f\"\\nüß¨ SELECTED FEATURES SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"Final selected features ({len(selected_features_rfe)}):\")\n",
    "    for i, feature in enumerate(selected_features_rfe, 1):\n",
    "        # Find importance score\n",
    "        importance_row = importance_results['feature_importance'][\n",
    "            importance_results['feature_importance']['feature'] == feature\n",
    "        ]\n",
    "        if len(importance_row) > 0:\n",
    "            importance_score = importance_row['importance'].iloc[0]\n",
    "            print(f\"  {i:2d}. {feature:25s} (importance: {importance_score:.4f})\")\n",
    "        else:\n",
    "            print(f\"  {i:2d}. {feature}\")\n",
    "\n",
    "# Save final summary\n",
    "summary_text_path = Path(CONFIG['output_paths']['reports']) / 'pipeline_summary.txt'\n",
    "with open(summary_text_path, 'w') as f:\n",
    "    f.write(\"PROTEIN ANALYSIS PIPELINE SUMMARY\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    f.write(f\"Execution Date: {datetime.now()}\\n\")\n",
    "    f.write(f\"Configuration: {CONFIG}\\n\\n\")\n",
    "    \n",
    "    f.write(\"RESULTS:\\n\")\n",
    "    f.write(f\"- Proteins selected: {len(selected_proteins) if 'selected_proteins' in globals() else 'N/A'}\\n\")\n",
    "    f.write(f\"- Final features: {len(selected_features_rfe) if 'selected_features_rfe' in globals() else 'N/A'}\\n\")\n",
    "    f.write(f\"- Best model: {best_model_type if 'best_model_type' in locals() else 'N/A'}\\n\")\n",
    "    \n",
    "    if 'final_metrics' in locals():\n",
    "        f.write(f\"- Final metrics: {final_metrics}\\n\")\n",
    "\n",
    "print(f\"\\nüíæ Results saved to:\")\n",
    "print(f\"  üìä JSON summary: {summary_path}\")\n",
    "print(f\"  üìù Text summary: {summary_text_path}\")\n",
    "\n",
    "# Display checkpoint system summary\n",
    "checkpoint_system.print_summary()\n",
    "\n",
    "print(f\"\\nüéâ Pipeline execution completed successfully!\")\n",
    "print(f\"‚è±Ô∏è  Total execution time: {checkpoint_system.get_total_execution_time():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0fd12",
   "metadata": {},
   "source": [
    "## Section 9: Checkpoint Management and Recovery\n",
    "\n",
    "Demonstrate checkpoint loading functionality, resume training from saved states, and validate checkpoint integrity across pipeline runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4fc50fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Checkpoint Management and Recovery Demo\n",
      "==================================================\n",
      "\n",
      "üìã Available checkpoints (5):\n",
      "  ‚úÖ 01_data_loading: 2025-10-17T20:37:52.076664\n",
      "  ‚úÖ 02_pwas_analysis: 2025-10-17T20:38:07.888061\n",
      "  ‚úÖ 03_feature_importance: 2025-10-17T20:39:59.376388\n",
      "  ‚úÖ 04_feature_selection: 2025-10-17T20:57:57.811384\n",
      "  ‚úÖ 05_model_training: 2025-10-17T21:04:57.974893\n",
      "\n",
      "üîÑ Demonstrating checkpoint recovery...\n",
      "\n",
      "üì• Loading data checkpoint...\n",
      "‚úÖ Checkpoint loaded: 01_data_loading\n",
      "   üìÖ Saved: 2025-10-17T20:37:52.076664\n",
      "  ‚úÖ Recovered data shapes:\n",
      "    Training: (2963, 2131)\n",
      "    Validation: (328, 2131)\n",
      "    Target distribution: {0: 2803, 1: 160}\n",
      "\n",
      "üì• Loading PWAS checkpoint...\n",
      "‚úÖ Checkpoint loaded: 02_pwas_analysis\n",
      "   üìÖ Saved: 2025-10-17T20:38:07.888061\n",
      "  ‚úÖ Recovered PWAS results:\n",
      "    Selected proteins: 200\n",
      "    Feature matrix shape: (2963, 200)\n",
      "\n",
      "üì• Loading feature selection checkpoint...\n",
      "‚úÖ Checkpoint loaded: 04_feature_selection\n",
      "   üìÖ Saved: 2025-10-17T20:57:57.811384\n",
      "  ‚úÖ Recovered RFE results:\n",
      "    Final features: 126\n",
      "    Final matrix shape: (2963, 126)\n",
      "\n",
      "üîç Checkpoint integrity validation:\n",
      "‚úÖ Checkpoint loaded: 01_data_loading\n",
      "   üìÖ Saved: 2025-10-17T20:37:52.076664\n",
      "  ‚úÖ 01_data_loading: Valid\n",
      "    - File size: 55271.0 KB\n",
      "‚úÖ Checkpoint loaded: 02_pwas_analysis\n",
      "   üìÖ Saved: 2025-10-17T20:38:07.888061\n",
      "  ‚úÖ 02_pwas_analysis: Valid\n",
      "    - File size: 174.9 KB\n",
      "‚úÖ Checkpoint loaded: 03_feature_importance\n",
      "   üìÖ Saved: 2025-10-17T20:39:59.376388\n",
      "  ‚úÖ 03_feature_importance: Valid\n",
      "    - File size: 4.9 KB\n",
      "‚úÖ Checkpoint loaded: 04_feature_selection\n",
      "   üìÖ Saved: 2025-10-17T20:57:57.811384\n",
      "  ‚úÖ 04_feature_selection: Valid\n",
      "    - File size: 3545.5 KB\n",
      "‚úÖ Checkpoint loaded: 05_model_training\n",
      "   üìÖ Saved: 2025-10-17T21:04:57.974893\n",
      "  ‚úÖ 05_model_training: Valid\n",
      "    - File size: 11172.6 KB\n",
      "\n",
      "üîÑ Pipeline restart demonstration:\n",
      "To restart the pipeline from any checkpoint, use:\n",
      "\n",
      "```python\n",
      "# Load checkpoint\n",
      "checkpoint_data = checkpoint_system.load_checkpoint('02_pwas_analysis')\n",
      "\n",
      "# Resume from that point\n",
      "X_train_selected = checkpoint_data['X_train_selected']\n",
      "selected_proteins = checkpoint_data['selected_proteins']\n",
      "\n",
      "# Continue with feature importance analysis...\n",
      "importance_analyzer = FeatureImportanceAnalyzer()\n",
      "# ... rest of pipeline\n",
      "```\n",
      "\n",
      "üìú Checkpoint recovery script created: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoint_recovery.py\n",
      "\n",
      "üìä Final Checkpoint System Summary:\n",
      "\n",
      "üìä CHECKPOINT SUMMARY - Run ID: unknown\n",
      "============================================================\n",
      "üìÅ Checkpoint directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "üíæ Total checkpoints: 5\n",
      "\n",
      "üìã Step Details:\n",
      "---------------------------------------------------------------------------\n",
      "üì¶ 01_data_loading\n",
      "   üìÖ Time: 2025-10-17T20:37:52.076664\n",
      "   üìù Description: Data loading and validation completed\n",
      "   üíæ Size: 54.0MB\n",
      "‚úÖ Checkpoint loaded: 01_data_loading\n",
      "   üìÖ Saved: 2025-10-17T20:37:52.076664\n",
      "   üìä Data: keys: 6\n",
      "\n",
      "üì¶ 02_pwas_analysis\n",
      "   üìÖ Time: 2025-10-17T20:38:07.888061\n",
      "   üìù Description: PWAS analysis and protein selection completed\n",
      "   üíæ Size: 174.9KB\n",
      "‚úÖ Checkpoint loaded: 02_pwas_analysis\n",
      "   üìÖ Saved: 2025-10-17T20:38:07.888061\n",
      "   üìä Data: keys: 4\n",
      "\n",
      "üì¶ 03_feature_importance\n",
      "   üìÖ Time: 2025-10-17T20:39:59.376388\n",
      "   üìù Description: Feature importance analysis completed\n",
      "   üíæ Size: 4.9KB\n",
      "‚úÖ Checkpoint loaded: 03_feature_importance\n",
      "   üìÖ Saved: 2025-10-17T20:39:59.376388\n",
      "   üìä Data: keys: 2\n",
      "\n",
      "üì¶ 04_feature_selection\n",
      "   üìÖ Time: 2025-10-17T20:57:57.811384\n",
      "   üìù Description: Feature selection and RFE completed\n",
      "   üíæ Size: 3.5MB\n",
      "‚úÖ Checkpoint loaded: 04_feature_selection\n",
      "   üìÖ Saved: 2025-10-17T20:57:57.811384\n",
      "   üìä Data: keys: 4\n",
      "\n",
      "üì¶ 05_model_training\n",
      "   üìÖ Time: 2025-10-17T21:04:57.974893\n",
      "   üìù Description: Model training and evaluation completed with 3 models including XGBoost\n",
      "   üíæ Size: 10.9MB\n",
      "‚úÖ Checkpoint loaded: 05_model_training\n",
      "   üìÖ Saved: 2025-10-17T21:04:57.974893\n",
      "   üìä Data: keys: 6\n",
      "\n",
      "\n",
      "üéØ Checkpoint management demonstration completed!\n",
      "üí° All checkpoints are ready for pipeline recovery and resumption.\n"
     ]
    }
   ],
   "source": [
    "print(\"üíæ Checkpoint Management and Recovery Demo\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# List all available checkpoints\n",
    "available_checkpoints = checkpoint_system.list_checkpoints()\n",
    "print(f\"\\nüìã Available checkpoints ({len(available_checkpoints)}):\")\n",
    "for checkpoint in available_checkpoints:\n",
    "    step_name = checkpoint['step_name']\n",
    "    metadata = checkpoint_system.get_checkpoint_info(step_name)\n",
    "    print(f\"  ‚úÖ {step_name}: {metadata.get('timestamp', 'Unknown time')}\")\n",
    "\n",
    "# Demonstrate checkpoint loading\n",
    "print(f\"\\nüîÑ Demonstrating checkpoint recovery...\")\n",
    "\n",
    "# Example: Load data loading checkpoint\n",
    "if checkpoint_system.checkpoint_exists('01_data_loading'):\n",
    "    print(f\"\\nüì• Loading data checkpoint...\")\n",
    "    data_checkpoint = checkpoint_system.load_checkpoint('01_data_loading')\n",
    "    print(f\"  ‚úÖ Recovered data shapes:\")\n",
    "    print(f\"    Training: {data_checkpoint['X_train'].shape}\")\n",
    "    print(f\"    Validation: {data_checkpoint['X_val'].shape}\")\n",
    "    print(f\"    Target distribution: {data_checkpoint['y_train'].value_counts().to_dict()}\")\n",
    "\n",
    "# Example: Load PWAS results\n",
    "if checkpoint_system.checkpoint_exists('02_pwas_analysis'):\n",
    "    print(f\"\\nüì• Loading PWAS checkpoint...\")\n",
    "    pwas_checkpoint_loaded = checkpoint_system.load_checkpoint('02_pwas_analysis')\n",
    "    print(f\"  ‚úÖ Recovered PWAS results:\")\n",
    "    print(f\"    Selected proteins: {len(pwas_checkpoint_loaded['selected_proteins'])}\")\n",
    "    print(f\"    Feature matrix shape: {pwas_checkpoint_loaded['X_train_selected'].shape}\")\n",
    "\n",
    "# Example: Load feature selection results  \n",
    "if checkpoint_system.checkpoint_exists('04_feature_selection'):\n",
    "    print(f\"\\nüì• Loading feature selection checkpoint...\")\n",
    "    rfe_checkpoint_loaded = checkpoint_system.load_checkpoint('04_feature_selection')\n",
    "    print(f\"  ‚úÖ Recovered RFE results:\")\n",
    "    print(f\"    Final features: {len(rfe_checkpoint_loaded['selected_features_rfe'])}\")\n",
    "    print(f\"    Final matrix shape: {rfe_checkpoint_loaded['X_train_final'].shape}\")\n",
    "\n",
    "# Validate checkpoint integrity\n",
    "print(f\"\\nüîç Checkpoint integrity validation:\")\n",
    "\n",
    "integrity_results = {}\n",
    "for checkpoint in available_checkpoints:\n",
    "    step_name = checkpoint['step_name']\n",
    "    try:\n",
    "        checkpoint_data = checkpoint_system.load_checkpoint(step_name)\n",
    "        metadata = checkpoint_system.get_checkpoint_info(step_name)\n",
    "        # Basic validation checks\n",
    "        is_valid = True\n",
    "        validation_messages = []\n",
    "        if checkpoint_data is None:\n",
    "            is_valid = False\n",
    "            validation_messages.append(\"Checkpoint data is None\")\n",
    "        if not metadata:\n",
    "            validation_messages.append(\"No metadata found\")\n",
    "        checkpoint_path = Path(checkpoint['file_path'])\n",
    "        if checkpoint_path.exists():\n",
    "            file_size = checkpoint_path.stat().st_size\n",
    "            if file_size == 0:\n",
    "                is_valid = False\n",
    "                validation_messages.append(\"Checkpoint file is empty\")\n",
    "            else:\n",
    "                validation_messages.append(f\"File size: {file_size/1024:.1f} KB\")\n",
    "        integrity_results[step_name] = {\n",
    "            'valid': is_valid,\n",
    "            'messages': validation_messages\n",
    "        }\n",
    "        status_icon = \"‚úÖ\" if is_valid else \"‚ùå\"\n",
    "        print(f\"  {status_icon} {step_name}: {'Valid' if is_valid else 'Invalid'}\")\n",
    "        for msg in validation_messages:\n",
    "            print(f\"    - {msg}\")\n",
    "    except Exception as e:\n",
    "        integrity_results[step_name] = {\n",
    "            'valid': False,\n",
    "            'messages': [f\"Error loading: {str(e)}\"]\n",
    "        }\n",
    "        print(f\"  ‚ùå {step_name}: Error - {str(e)}\")\n",
    "\n",
    "# Demonstrate pipeline restart from checkpoint\n",
    "print(f\"\\nüîÑ Pipeline restart demonstration:\")\n",
    "print(f\"To restart the pipeline from any checkpoint, use:\")\n",
    "print(f\"\")\n",
    "print(f\"```python\")\n",
    "print(f\"# Load checkpoint\")\n",
    "print(f\"checkpoint_data = checkpoint_system.load_checkpoint('02_pwas_analysis')\")\n",
    "print(f\"\")\n",
    "print(f\"# Resume from that point\")\n",
    "print(f\"X_train_selected = checkpoint_data['X_train_selected']\")\n",
    "print(f\"selected_proteins = checkpoint_data['selected_proteins']\")\n",
    "print(f\"\")\n",
    "print(f\"# Continue with feature importance analysis...\")\n",
    "print(f\"importance_analyzer = FeatureImportanceAnalyzer()\")\n",
    "print(f\"# ... rest of pipeline\")\n",
    "print(f\"```\")\n",
    "\n",
    "# Create checkpoint recovery script\n",
    "recovery_script_path = Path(CONFIG['output_paths']['base_dir']) / 'checkpoint_recovery.py'\n",
    "recovery_script = f'''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Checkpoint Recovery Script\n",
    "==========================\n",
    "\n",
    "This script demonstrates how to recover and resume the pipeline from any checkpoint.\n",
    "Generated automatically by the pipeline orchestrator.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/itg/oleg.vlasovets/projects/protein-benchmark')\n",
    "\n",
    "from pipeline import CheckpointSystem\n",
    "\n",
    "# Initialize checkpoint system\n",
    "checkpoint_system = CheckpointSystem('{CONFIG['output_paths']['checkpoints']}')\n",
    "\n",
    "# List available checkpoints\n",
    "print(\"Available checkpoints:\")\n",
    "for checkpoint in checkpoint_system.list_checkpoints():\n",
    "    step_name = checkpoint['step_name']\n",
    "    metadata = checkpoint_system.get_checkpoint_info(step_name)\n",
    "    print(f\"  - {{step_name}}: {{metadata.get('timestamp', 'Unknown')}}\")\n",
    "\n",
    "# Example: Resume from PWAS analysis\n",
    "if checkpoint_system.checkpoint_exists('02_pwas_analysis'):\n",
    "    print(\"\\\\nResuming from PWAS analysis checkpoint...\")\n",
    "    pwas_data = checkpoint_system.load_checkpoint('02_pwas_analysis')\n",
    "    # Extract recovered data\n",
    "    selected_proteins = pwas_data['selected_proteins']\n",
    "    X_train_selected = pwas_data['X_train_selected']\n",
    "    print(f\"Recovered {{len(selected_proteins)}} selected proteins\")\n",
    "    print(f\"Feature matrix shape: {{X_train_selected.shape}}\")\n",
    "    # Continue with next step...\n",
    "    # (Add your continuation logic here)\n",
    "else:\n",
    "    print(\"PWAS checkpoint not found. Run the full pipeline first.\")\n",
    "'''\n",
    "\n",
    "with open(recovery_script_path, 'w') as f:\n",
    "    f.write(recovery_script)\n",
    "\n",
    "print(f\"\\nüìú Checkpoint recovery script created: {recovery_script_path}\")\n",
    "\n",
    "# Final checkpoint summary\n",
    "print(f\"\\nüìä Final Checkpoint System Summary:\")\n",
    "checkpoint_system.print_summary()\n",
    "\n",
    "print(f\"\\nüéØ Checkpoint management demonstration completed!\")\n",
    "print(f\"üí° All checkpoints are ready for pipeline recovery and resumption.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fede2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook successfully demonstrates the complete protein analysis pipeline, reproducing the R methodology with modular Python components. The pipeline includes:\n",
    "\n",
    "### ‚úÖ **Completed Steps:**\n",
    "1. **Data Loading**: Loaded protein expression and phenotype data with validation\n",
    "2. **PWAS Analysis**: Performed protein-wide association study with R fallback strategy\n",
    "3. **Feature Importance**: Ranked proteins using Random Forest importance\n",
    "4. **Feature Selection**: Applied RFE to select optimal feature set\n",
    "5. **Model Training**: Trained and compared multiple ML models\n",
    "6. **Results Analysis**: Generated comprehensive performance metrics\n",
    "7. **Checkpoint System**: Implemented robust checkpoint management for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99959e21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
