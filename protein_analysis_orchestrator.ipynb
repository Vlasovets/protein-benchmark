{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74cf8003",
   "metadata": {},
   "source": [
    "# Protein Analysis Pipeline Orchestrator\n",
    "\n",
    "This notebook orchestrates the complete protein-based machine learning analysis pipeline, reproducing the R methodology with modular Python components.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This pipeline implements:\n",
    "1. **Data Loading & Validation** - Load protein expression and phenotype data\n",
    "2. **PWAS Analysis** - Protein-Wide Association Study with multiple testing correction\n",
    "3. **Feature Importance** - Random Forest importance ranking\n",
    "4. **Feature Selection** - Recursive Feature Elimination (RFE)\n",
    "5. **Model Training** - Multiple ML models with cross-validation\n",
    "6. **Results Analysis** - Performance metrics and visualization\n",
    "7. **Checkpoint System** - Save/load intermediate results\n",
    "\n",
    "The analysis reproduces the methodology from:\n",
    "`/home/itg/oleg.vlasovets/projects/protein-benchmark/archive/R_analysis/2_train_agnostic_with_checkpoints.Rmd`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296edeee",
   "metadata": {},
   "source": [
    "### Activate conda env protein-benchmark and run jupyter inside of that env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03dfd1",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries and Modules\n",
    "\n",
    "Import necessary Python libraries and custom pipeline modules for each analysis step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a632eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Warning: imbalanced-learn not installed. ROSE sampling will not be available.\n",
      "   Install with: pip install imbalanced-learn\n",
      "âœ… Successfully imported all pipeline modules\n",
      "ğŸ“… Notebook started at: 2025-10-17 20:30:26.376392\n",
      "ğŸ’» System info: {'platform': 'Linux-5.14.0-570.25.1.el9_6.x86_64-x86_64-with-glibc2.34', 'python_version': '3.10.19', 'cpu_count': 32, 'memory_total': '754.0 GB', 'memory_available': '660.0 GB'}\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import custom pipeline modules\n",
    "sys.path.append('/home/itg/oleg.vlasovets/projects/protein-benchmark')\n",
    "\n",
    "try:\n",
    "    from pipeline import (\n",
    "        DataLoader, PWASAnalyzer, FeatureImportanceAnalyzer,\n",
    "        FeatureSelector, ModelTrainer, CheckpointSystem,\n",
    "        validate_data_compatibility, create_results_summary,\n",
    "        print_pipeline_summary, timer, get_system_info\n",
    "    )\n",
    "    print(\"âœ… Successfully imported all pipeline modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Error importing pipeline modules: {e}\")\n",
    "    print(\"Make sure the pipeline modules are properly installed\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(f\"ğŸ“… Notebook started at: {datetime.now()}\")\n",
    "print(f\"ğŸ’» System info: {get_system_info() if 'get_system_info' in globals() else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c899e1",
   "metadata": {},
   "source": [
    "## Section 2: Load and Validate Configuration\n",
    "\n",
    "Set up configuration parameters and validate input paths, model parameters, and checkpoint settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5fae2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in ./miniconda3/envs/protein-benchmark/lib/python3.10/site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e879f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run\n",
      "ğŸ“ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "ğŸ“ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/plots\n",
      "ğŸ“ Created directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports\n",
      "\n",
      "ğŸ“‹ Validating input files...\n",
      "âœ… protein_train: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_train.csv (109.4 MB)\n",
      "âœ… phenotype_train: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_train.csv (0.3 MB)\n",
      "âœ… protein_val: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_val.csv (12.1 MB)\n",
      "âœ… phenotype_val: /home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_val.csv (0.0 MB)\n",
      "\n",
      "ğŸ¯ Target variable: oa_status\n",
      "ğŸ§¬ Prediction mode: prot_only\n",
      "ğŸ² Random seed: 42\n",
      "ğŸ“Š Cross-validation folds: 10\n",
      "ğŸ¤– Models to compare: random_forest, logistic_regression, xgboost\n",
      "ğŸ’¾ Results will be saved to: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    # Data paths (updated to use raw UKBB data files from R analysis)\n",
    "    'data_paths': {\n",
    "        'protein_train': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_train.csv',\n",
    "        'phenotype_train': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_train.csv',\n",
    "        'protein_val': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_proteins_val.csv',\n",
    "        'phenotype_val': '/home/itg/oleg.vlasovets/projects/protein-benchmark/data/raw/ukbb_phenotypes_val.csv'\n",
    "    },\n",
    "    \n",
    "    # Analysis parameters\n",
    "    'analysis_params': {\n",
    "        'target_column': 'oa_status',\n",
    "        'pred_mode': 'prot_only',  # 'prot_only', 'sexagebmi', 'comb'\n",
    "        'random_state': 42,\n",
    "        'cv_folds': 10\n",
    "    },\n",
    "    \n",
    "    # PWAS parameters  \n",
    "    'pwas_params': {\n",
    "        'fdr_threshold': 0.05,\n",
    "        'p_threshold': 0.05,\n",
    "        'max_proteins': 200\n",
    "    },\n",
    "    \n",
    "    # Feature selection parameters\n",
    "    'feature_params': {\n",
    "        'rf_n_estimators': 500,\n",
    "        'rfe_n_features': 20,\n",
    "        'rfe_step': 1,\n",
    "        'use_rfe_cv': True\n",
    "    },\n",
    "    \n",
    "    # Model parameters\n",
    "    'model_params': {\n",
    "        'hyperparameter_tuning': False,\n",
    "        'scale_features': False,\n",
    "        'model_types': ['random_forest', 'logistic_regression', 'xgboost'] \n",
    "    },\n",
    "    \n",
    "    # Output paths\n",
    "    'output_paths': {\n",
    "        'base_dir': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run',\n",
    "        'checkpoints': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints',\n",
    "        'plots': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/plots',\n",
    "        'reports': '/home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "for path_key, path_value in CONFIG['output_paths'].items():\n",
    "    Path(path_value).mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"ğŸ“ Created directory: {path_value}\")\n",
    "\n",
    "# Validate input files exist\n",
    "print(\"\\nğŸ“‹ Validating input files...\")\n",
    "for file_key, file_path in CONFIG['data_paths'].items():\n",
    "    if Path(file_path).exists():\n",
    "        file_size = Path(file_path).stat().st_size / (1024**2)  # MB\n",
    "        print(f\"âœ… {file_key}: {file_path} ({file_size:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"âŒ {file_key}: {file_path} (NOT FOUND)\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Target variable: {CONFIG['analysis_params']['target_column']}\")\n",
    "print(f\"ğŸ§¬ Prediction mode: {CONFIG['analysis_params']['pred_mode']}\")\n",
    "print(f\"ğŸ² Random seed: {CONFIG['analysis_params']['random_state']}\")\n",
    "print(f\"ğŸ“Š Cross-validation folds: {CONFIG['analysis_params']['cv_folds']}\")\n",
    "print(f\"ğŸ¤– Models to compare: {', '.join(CONFIG['model_params']['model_types'])}\")\n",
    "print(f\"ğŸ’¾ Results will be saved to: {CONFIG['output_paths']['base_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fbd0e7",
   "metadata": {},
   "source": [
    "## Section 3: Data Loading and Preprocessing\n",
    "\n",
    "Load protein benchmark data, perform preprocessing steps, and prepare training/validation datasets using the data processing module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1c490b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Checkpoint directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "ğŸ“¥ Loading protein expression and phenotype data...\n",
      "ğŸ“¥ Loading data for prediction mode: prot_only\n",
      "  ğŸ“Š Loading protein expression matrices...\n",
      "  ğŸ“‹ Loading phenotype data...\n",
      "  âš ï¸  Found 11456 missing values in training phenotypes\n",
      "  âš ï¸  Found 1261 missing values in validation phenotypes\n",
      "\n",
      "ğŸ“Š DATA LOADING SUMMARY\n",
      "  ğŸ¯ Prediction mode: prot_only\n",
      "  ğŸ‹ï¸  Training: 2963 samples Ã— 2131 features\n",
      "  ğŸ§ª Validation: 328 samples Ã— 2131 features\n",
      "  ğŸ“‹ Target variable: oa_status\n",
      "  ğŸª Training target distribution: {0: 2803, 1: 160}\n",
      "  ğŸª Validation target distribution: {0: 311, 1: 17}\n",
      "  ğŸ§¬ Features: ['A1BG', 'AAMDC', 'AARSD1', 'ABCA2', 'ABHD14B'] ... ['ZFYVE19', 'ZHX2', 'ZNRD2', 'ZNRF4', 'ZP3']\n",
      "\n",
      "ğŸ“Š Data loaded successfully!\n",
      "ğŸ‹ï¸  Training: 2963 samples Ã— 2131 features\n",
      "ğŸ§ª Validation: 328 samples Ã— 2131 features\n",
      "ğŸ¯ Target distribution (train): {0: 2803, 1: 160}\n",
      "ğŸ¯ Target distribution (val): {0: 311, 1: 17}\n",
      "âœ… Data validation passed!\n",
      "âœ… Checkpoint saved: 01_data_loading\n",
      "   ğŸ“„ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/01_data_loading.pkl\n",
      "   ğŸ—ƒï¸  DataFrame 'X_train': (2963, 2131) shape\n",
      "   ğŸ—ƒï¸  DataFrame 'X_val': (328, 2131) shape\n",
      "ğŸ’¾ Data loading checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize checkpoint system\n",
    "checkpoint_system = CheckpointSystem(CONFIG['output_paths']['checkpoints'])\n",
    "\n",
    "# Initialize data loader\n",
    "data_loader = DataLoader(CONFIG['output_paths']['base_dir'])\n",
    "\n",
    "print(\"ğŸ“¥ Loading protein expression and phenotype data...\")\n",
    "\n",
    "# Load data matrices\n",
    "data_dict = data_loader.load_matrices(\n",
    "    protein_train_path=CONFIG['data_paths']['protein_train'],\n",
    "    phenotype_train_path=CONFIG['data_paths']['phenotype_train'],\n",
    "    protein_val_path=CONFIG['data_paths']['protein_val'],\n",
    "    phenotype_val_path=CONFIG['data_paths']['phenotype_val'],\n",
    "    pred_mode=CONFIG['analysis_params']['pred_mode'],\n",
    "    target_column=CONFIG['analysis_params']['target_column']\n",
    ")\n",
    "\n",
    "# Extract matrices for easier access\n",
    "X_train = data_dict['p_mtx_traintest']\n",
    "y_train = data_dict['pheno_train_test'][CONFIG['analysis_params']['target_column']]\n",
    "X_val = data_dict['p_mtx_val'] \n",
    "y_val = data_dict['pheno_val'][CONFIG['analysis_params']['target_column']]\n",
    "\n",
    "print(f\"\\nğŸ“Š Data loaded successfully!\")\n",
    "print(f\"ğŸ‹ï¸  Training: {X_train.shape[0]} samples Ã— {X_train.shape[1]} features\")\n",
    "print(f\"ğŸ§ª Validation: {X_val.shape[0]} samples Ã— {X_val.shape[1]} features\")\n",
    "print(f\"ğŸ¯ Target distribution (train): {y_train.value_counts().to_dict()}\")\n",
    "print(f\"ğŸ¯ Target distribution (val): {y_val.value_counts().to_dict()}\")\n",
    "\n",
    "# Validate data compatibility\n",
    "validation_results = validate_data_compatibility(\n",
    "    X_train, data_dict['pheno_train_test'], \n",
    "    CONFIG['analysis_params']['target_column']\n",
    ")\n",
    "\n",
    "if validation_results['compatible']:\n",
    "    print(\"âœ… Data validation passed!\")\n",
    "else:\n",
    "    print(\"âš ï¸ Data validation warnings:\")\n",
    "    for warning in validation_results['warnings']:\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "# Save data loading checkpoint\n",
    "checkpoint_data = {\n",
    "    'data_dict': data_dict,\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_val': X_val,\n",
    "    'y_val': y_val,\n",
    "    'validation_results': validation_results\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(checkpoint_data, '01_data_loading', \"Data loading and validation completed\")\n",
    "print(\"ğŸ’¾ Data loading checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f63f5d9",
   "metadata": {},
   "source": [
    "#### TO DO: check missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc465119",
   "metadata": {},
   "source": [
    "## Section 4: PWAS Analysis (Protein-Wide Association Study)\n",
    "\n",
    "Perform PWAS analysis to identify proteins significantly associated with the target variable, implementing the R fallback strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae858475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¬ Starting PWAS analysis...\n",
      "ğŸ§¬ Starting PWAS analysis...\n",
      "  ğŸ¯ Target: oa_status\n",
      "  ğŸ§ª Proteins: 2131\n",
      "  ğŸ‘¥ Samples: 2963\n",
      "  ğŸ”§ Covariates: ['Age_at_recruitment', 'Sex', 'bmi', 'mean_NPX', 'Plate0', 'Plate2', 'Plate3']\n",
      "    ğŸ”§ Sex encoding: {'Female': np.int64(0), 'Male': np.int64(1)}\n",
      "  ğŸ”§ Using covariates: ['Age_at_recruitment', 'Sex_encoded', 'bmi', 'mean_NPX', 'Plate0', 'Plate2', 'Plate3']\n",
      "  ğŸ“Š Covariate matrix shape: (2963, 7)\n",
      "    Age_at_recruitment: min=39.000, max=70.000, has_nan=False\n",
      "    Sex_encoded: min=0.000, max=1.000, has_nan=False\n",
      "    bmi: min=16.159, max=53.370, has_nan=False\n",
      "    mean_NPX: min=-0.697, max=0.969, has_nan=False\n",
      "    Plate0: min=890000000001.000, max=890000000672.000, has_nan=False\n",
      "    Plate2: min=890000000578.000, max=890000000671.000, has_nan=False\n",
      "    Plate3: min=890000000633.000, max=890000000671.000, has_nan=False\n",
      "  ğŸ”„ Testing 2131 proteins...\n",
      "    Processing protein 1/2131\n",
      "    Processing protein 501/2131\n",
      "    Processing protein 1001/2131\n",
      "    Processing protein 1501/2131\n",
      "    Processing protein 2001/2131\n",
      "\n",
      "ğŸ§¬ PWAS ANALYSIS SUMMARY\n",
      "  ğŸ”¬ Total proteins tested: 2131\n",
      "  âœ… Valid associations: 2131\n",
      "  ğŸ¯ FDR significant (< 0.05): 952\n",
      "  ğŸ“Š Nominal significant (< 0.05): 1105\n",
      "  ğŸ† Best p-value: 5.52e-23\n",
      "  ğŸ¥‡ Top protein: ELN (p = 5.52e-23)\n",
      "\n",
      "  ğŸ“‹ Top 10 proteins:\n",
      "     1. ELN             p=5.52e-23 OR=1.000\n",
      "     2. TNFRSF10B       p=7.53e-19 OR=1.000\n",
      "     3. ADM             p=2.44e-18 OR=1.000\n",
      "     4. TREM2           p=1.21e-17 OR=1.000\n",
      "     5. IGFBP4          p=8.05e-16 OR=1.000\n",
      "     6. CXCL17          p=1.06e-15 OR=1.000\n",
      "     7. FUT3_FUT5       p=5.59e-15 OR=1.000\n",
      "     8. GFRA1           p=1.06e-14 OR=1.000\n",
      "     9. LAMP3           p=1.23e-14 OR=1.000\n",
      "    10. CLMP            p=3.66e-14 OR=1.000\n",
      "\n",
      "ğŸ¯ Applying R fallback strategy for protein selection:\n",
      "ğŸ¯ Selected 952 FDR-significant proteins\n",
      "  âœ‚ï¸  Limiting to top 200 proteins\n",
      "\n",
      "âœ… Selected 200 proteins for analysis\n",
      "ğŸ† Top 10 selected proteins:\n",
      "   1. ELN (p = 5.52e-23) ***\n",
      "   2. TNFRSF10B (p = 7.53e-19) ***\n",
      "   3. ADM (p = 2.44e-18) ***\n",
      "   4. TREM2 (p = 1.21e-17) ***\n",
      "   5. IGFBP4 (p = 8.05e-16) ***\n",
      "   6. CXCL17 (p = 1.06e-15) ***\n",
      "   7. FUT3_FUT5 (p = 5.59e-15) ***\n",
      "   8. GFRA1 (p = 1.06e-14) ***\n",
      "   9. LAMP3 (p = 1.23e-14) ***\n",
      "  10. CLMP (p = 3.66e-14) ***\n",
      "\n",
      "ğŸ“Š Selected feature matrices:\n",
      "ğŸ‹ï¸  Training: 2963 samples Ã— 200 features\n",
      "ğŸ§ª Validation: 328 samples Ã— 200 features\n",
      "âœ… Checkpoint saved: 02_pwas_analysis\n",
      "   ğŸ“„ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/02_pwas_analysis.pkl\n",
      "   ğŸ—ƒï¸  DataFrame 'X_train_selected': (2963, 200) shape\n",
      "   ğŸ—ƒï¸  DataFrame 'X_val_selected': (328, 200) shape\n",
      "ğŸ’¾ PWAS analysis checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize PWAS analyzer\n",
    "pwas_analyzer = PWASAnalyzer()\n",
    "\n",
    "print(\"ğŸ§¬ Starting PWAS analysis...\")\n",
    "\n",
    "# Perform PWAS analysis with corrected implementation\n",
    "pwas_results = pwas_analyzer.perform_pwas(\n",
    "    protein_matrix=X_train,\n",
    "    phenotype_data=data_dict['pheno_train_test'],\n",
    "    target_column=CONFIG['analysis_params']['target_column'],\n",
    "    fdr_threshold=CONFIG['pwas_params']['fdr_threshold'],\n",
    "    p_threshold=CONFIG['pwas_params']['p_threshold']\n",
    ")\n",
    "\n",
    "# Check if we got valid results\n",
    "if len(pwas_results['results']) == 0:\n",
    "    print(\"âš ï¸ No PWAS results obtained. This may be due to:\")\n",
    "    print(\"  - Categorical variable encoding issues\")\n",
    "    print(\"  - Insufficient sample size\") \n",
    "    print(\"  - Data quality issues\")\n",
    "    print(\"\\nUsing all proteins for downstream analysis...\")\n",
    "    \n",
    "    # Fallback: use all proteins\n",
    "    selected_proteins = X_train.columns.tolist()[:CONFIG['pwas_params']['max_proteins']]\n",
    "    print(f\"ğŸ“Š Selected {len(selected_proteins)} proteins (all available, limited by max_proteins)\")\n",
    "    \n",
    "else:\n",
    "    # Implement R fallback strategy for protein selection\n",
    "    print(\"\\nğŸ¯ Applying R fallback strategy for protein selection:\")\n",
    "\n",
    "    # Strategy 1: Try FDR-significant proteins\n",
    "    selected_proteins = pwas_analyzer.get_selected_proteins(\n",
    "        selection_strategy=\"fdr_significant\",\n",
    "        max_proteins=CONFIG['pwas_params']['max_proteins']\n",
    "    )\n",
    "\n",
    "    if len(selected_proteins) == 0:\n",
    "        print(\"  ğŸ“‰ No FDR-significant proteins found. Trying nominal significance...\")\n",
    "        # Strategy 2: Try nominally significant proteins\n",
    "        selected_proteins = pwas_analyzer.get_selected_proteins(\n",
    "            selection_strategy=\"nominal_significant\", \n",
    "            max_proteins=CONFIG['pwas_params']['max_proteins']\n",
    "        )\n",
    "\n",
    "    if len(selected_proteins) == 0:\n",
    "        print(\"  ğŸ“‰ No nominally significant proteins found. Using top proteins by p-value...\")\n",
    "        # Strategy 3: Use top proteins by p-value\n",
    "        selected_proteins = pwas_analyzer.get_selected_proteins(\n",
    "            selection_strategy=\"top_n\",\n",
    "            max_proteins=CONFIG['pwas_params']['max_proteins']\n",
    "        )\n",
    "\n",
    "    print(f\"\\nâœ… Selected {len(selected_proteins)} proteins for analysis\")\n",
    "    print(f\"ğŸ† Top 10 selected proteins:\")\n",
    "    for i, protein in enumerate(selected_proteins[:10], 1):\n",
    "        # Get p-value for this protein\n",
    "        results_df = pwas_results['results']\n",
    "        protein_row = results_df[results_df['protein'] == protein]\n",
    "        if len(protein_row) > 0:\n",
    "            p_val = protein_row['p_value'].iloc[0]\n",
    "            fdr_sig = \"***\" if protein_row['fdr_significant'].iloc[0] else \"\"\n",
    "            nom_sig = \"**\" if protein_row['nominal_significant'].iloc[0] else \"\"\n",
    "            sig_marker = fdr_sig or nom_sig\n",
    "            print(f\"  {i:2d}. {protein} (p = {p_val:.2e}) {sig_marker}\")\n",
    "\n",
    "# Create feature matrix with selected proteins\n",
    "X_train_selected = X_train[selected_proteins].copy()\n",
    "X_val_selected = X_val[selected_proteins].copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š Selected feature matrices:\")\n",
    "print(f\"ğŸ‹ï¸  Training: {X_train_selected.shape[0]} samples Ã— {X_train_selected.shape[1]} features\")\n",
    "print(f\"ğŸ§ª Validation: {X_val_selected.shape[0]} samples Ã— {X_val_selected.shape[1]} features\")\n",
    "\n",
    "# Save PWAS checkpoint\n",
    "pwas_checkpoint = {\n",
    "    'pwas_results': pwas_results,\n",
    "    'selected_proteins': selected_proteins,\n",
    "    'X_train_selected': X_train_selected,\n",
    "    'X_val_selected': X_val_selected\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(pwas_checkpoint, '02_pwas_analysis', \"PWAS analysis and protein selection completed\")\n",
    "print(\"ğŸ’¾ PWAS analysis checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40644d46",
   "metadata": {},
   "source": [
    "## Section 5: Feature Importance Analysis\n",
    "\n",
    "Analyze feature importance using Random Forest to rank the selected proteins by their predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72197ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ² Starting Random Forest feature importance analysis...\n",
      "ğŸŒ² Starting Random Forest feature importance analysis...\n",
      "  ğŸ“Š Features: 200\n",
      "  ğŸ‘¥ Samples: 2963\n",
      "  ğŸŒ³ Trees: 500\n",
      "  ğŸ”„ Training Random Forest...\n",
      "  ğŸ“ˆ Evaluating model performance...\n",
      "\n",
      "ğŸŒ² RANDOM FOREST IMPORTANCE SUMMARY\n",
      "  ğŸ¯ Training AUC: 1.0000\n",
      "  ğŸ“Š CV AUC: 0.8118 Â± 0.0519\n",
      "  ğŸ² OOB Score: 0.9457\n",
      "\n",
      "  ğŸ† Top 10 most important features:\n",
      "     1. TREM2                0.0206\n",
      "     2. ADM                  0.0196\n",
      "     3. BGLAP                0.0173\n",
      "     4. ELN                  0.0165\n",
      "     5. CA6                  0.0131\n",
      "     6. TNFRSF10B            0.0121\n",
      "     7. GDF15                0.0115\n",
      "     8. PGF                  0.0113\n",
      "     9. CCL23                0.0112\n",
      "    10. SIGLEC8              0.0107\n",
      "\n",
      "  ğŸ“ˆ Importance distribution:\n",
      "    Mean: 0.0050\n",
      "    Std:  0.0030\n",
      "    Max:  0.0206\n",
      "    Min:  0.0017\n",
      "ğŸ¯ Selected top 20 features by importance\n",
      "\n",
      "ğŸ† Top 20 features by RF importance:\n",
      "   1. TREM2                0.0206\n",
      "   2. ADM                  0.0196\n",
      "   3. BGLAP                0.0173\n",
      "   4. ELN                  0.0165\n",
      "   5. CA6                  0.0131\n",
      "   6. TNFRSF10B            0.0121\n",
      "   7. GDF15                0.0115\n",
      "   8. PGF                  0.0113\n",
      "   9. CCL23                0.0112\n",
      "  10. SIGLEC8              0.0107\n",
      "  11. DNER                 0.0106\n",
      "  12. AMY1A_AMY1B_AMY1C    0.0104\n",
      "  13. COL9A1               0.0103\n",
      "  14. CXCL17               0.0103\n",
      "  15. RGMA                 0.0097\n",
      "  16. LPO                  0.0097\n",
      "  17. CXCL14               0.0094\n",
      "  18. AMY2A                0.0092\n",
      "  19. EDA2R                0.0088\n",
      "  20. GFRA1                0.0088\n",
      "\n",
      "ğŸ“Š Feature Importance Distribution:\n",
      "\n",
      "ğŸ“Š Top 20 Feature Importances:\n",
      "  ============================================================\n",
      "   1. TREM2           |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 0.0206\n",
      "   2. ADM             |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘| 0.0196\n",
      "   3. BGLAP           |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0173\n",
      "   4. ELN             |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0165\n",
      "   5. CA6             |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0131\n",
      "   6. TNFRSF10B       |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0121\n",
      "   7. GDF15           |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0115\n",
      "   8. PGF             |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0113\n",
      "   9. CCL23           |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0112\n",
      "  10. SIGLEC8         |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0107\n",
      "  11. DNER            |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0106\n",
      "  12. AMY1A_AMY1B_AMY1C |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0104\n",
      "  13. COL9A1          |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0103\n",
      "  14. CXCL17          |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0103\n",
      "  15. RGMA            |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0097\n",
      "  16. LPO             |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0097\n",
      "  17. CXCL14          |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0094\n",
      "  18. AMY2A           |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0092\n",
      "  19. EDA2R           |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0088\n",
      "  20. GFRA1           |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘| 0.0088\n",
      "âœ… Checkpoint saved: 03_feature_importance\n",
      "   ğŸ“„ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/03_feature_importance.pkl\n",
      "ğŸ’¾ Feature importance checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature importance analyzer\n",
    "importance_analyzer = FeatureImportanceAnalyzer(\n",
    "    random_state=CONFIG['analysis_params']['random_state']\n",
    ")\n",
    "\n",
    "print(\"ğŸŒ² Starting Random Forest feature importance analysis...\")\n",
    "\n",
    "# Analyze feature importance\n",
    "importance_results = importance_analyzer.analyze_rf_importance(\n",
    "    X_train=X_train_selected,\n",
    "    y_train=y_train,\n",
    "    n_estimators=CONFIG['feature_params']['rf_n_estimators'],\n",
    "    cv_folds=CONFIG['analysis_params']['cv_folds']\n",
    ")\n",
    "\n",
    "# Get top features by importance\n",
    "top_features_importance = importance_analyzer.get_top_features(\n",
    "    n_features=CONFIG['feature_params']['rfe_n_features'],\n",
    "    method='top_n'\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ† Top {len(top_features_importance)} features by RF importance:\")\n",
    "importance_df = importance_results['feature_importance']\n",
    "for i, row in importance_df.head(CONFIG['feature_params']['rfe_n_features']).iterrows():\n",
    "    print(f\"  {i+1:2d}. {row['feature']:20s} {row['importance']:.4f}\")\n",
    "\n",
    "# Visualize feature importance (text-based)\n",
    "print(f\"\\nğŸ“Š Feature Importance Distribution:\")\n",
    "importance_analyzer._print_text_importance_plot(20)\n",
    "\n",
    "# Save importance checkpoint - FIX THE PARAMETER ORDER\n",
    "importance_checkpoint = {\n",
    "    'importance_results': importance_results,\n",
    "    'top_features_importance': top_features_importance\n",
    "}\n",
    "\n",
    "# Correct parameter order: data, step_name, description\n",
    "checkpoint_system.save_checkpoint(\n",
    "    importance_checkpoint, \n",
    "    '03_feature_importance', \n",
    "    \"Feature importance analysis completed\"\n",
    ")\n",
    "print(\"ğŸ’¾ Feature importance checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccba0b",
   "metadata": {},
   "source": [
    "## Section 6: Recursive Feature Elimination (RFE)\n",
    "\n",
    "Perform RFE to systematically select the most predictive features, reducing dimensionality while maintaining performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7275a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Starting Recursive Feature Elimination...\n",
      "ğŸ”§ Starting Recursive Feature Elimination...\n",
      "  ğŸ“Š Initial features: 200\n",
      "  ğŸ¯ Target features: auto (CV)\n",
      "  ğŸ—ï¸  Estimator: random_forest\n",
      "  ğŸ”„ Running RFECV with 10-fold CV...\n",
      "  ğŸ“ˆ Evaluating feature selection performance...\n",
      "\n",
      "ğŸ”§ RFE FEATURE SELECTION SUMMARY\n",
      "  ğŸ“Š Features selected: 126/200\n",
      "  ğŸ¯ Selection ratio: 63.00%\n",
      "  ğŸ—ï¸  Estimator: random_forest\n",
      "\n",
      "  ğŸ“ˆ Performance with selected features:\n",
      "    Training AUC: 1.0000\n",
      "    CV AUC: 0.8178 Â± 0.0522\n",
      "\n",
      "  ğŸ† Selected features:\n",
      "     1. ELN\n",
      "     2. TNFRSF10B\n",
      "     3. ADM\n",
      "     4. TREM2\n",
      "     5. IGFBP4\n",
      "     6. CXCL17\n",
      "     7. FUT3_FUT5\n",
      "     8. GFRA1\n",
      "     9. LAMP3\n",
      "    10. PGF\n",
      "    ... and 116 more\n",
      "\n",
      "  ğŸ“Š RFECV Results:\n",
      "    Optimal features: 126\n",
      "    Best CV score: No scores available\n",
      "\n",
      "ğŸ¯ RFE selected 126 features:\n",
      "   1. ELN\n",
      "   2. TNFRSF10B\n",
      "   3. ADM\n",
      "   4. TREM2\n",
      "   5. IGFBP4\n",
      "   6. CXCL17\n",
      "   7. FUT3_FUT5\n",
      "   8. GFRA1\n",
      "   9. LAMP3\n",
      "  10. PGF\n",
      "  11. LECT2\n",
      "  12. COL9A1\n",
      "  13. EDA2R\n",
      "  14. GDF15\n",
      "  15. CCN3\n",
      "  16. DNER\n",
      "  17. FSTL3\n",
      "  18. PIK3IP1\n",
      "  19. COL18A1\n",
      "  20. CD302\n",
      "  21. CXCL14\n",
      "  22. COL6A3\n",
      "  23. CA6\n",
      "  24. SIGLEC8\n",
      "  25. CD276\n",
      "  26. LGALS9\n",
      "  27. CD300LF\n",
      "  28. GALNT10\n",
      "  29. CXCL9\n",
      "  30. TNFRSF9\n",
      "  31. PRG2\n",
      "  32. EFNA1\n",
      "  33. CD300A\n",
      "  34. CCL23\n",
      "  35. CD99L2\n",
      "  36. PLAUR\n",
      "  37. RBFOX3\n",
      "  38. SCARF2\n",
      "  39. ACTA2\n",
      "  40. LPO\n",
      "  41. CKB\n",
      "  42. SHISA5\n",
      "  43. LILRB4\n",
      "  44. AMBP\n",
      "  45. HLA.E\n",
      "  46. TNFRSF12A\n",
      "  47. IGFBPL1\n",
      "  48. RARRES2\n",
      "  49. ULBP2\n",
      "  50. CDCP1\n",
      "  51. PROK1\n",
      "  52. CLEC4D\n",
      "  53. RNF149\n",
      "  54. CEACAM1\n",
      "  55. WNT9A\n",
      "  56. CCL27\n",
      "  57. AMY2A\n",
      "  58. CHIT1\n",
      "  59. LRRN1\n",
      "  60. FBLN2\n",
      "  61. ADIPOQ\n",
      "  62. CPPED1\n",
      "  63. AMY2B\n",
      "  64. MMP12\n",
      "  65. ADAM9\n",
      "  66. BOC\n",
      "  67. TFF3\n",
      "  68. BGLAP\n",
      "  69. LTA4H\n",
      "  70. HAVCR1\n",
      "  71. PALM2\n",
      "  72. HSPB6\n",
      "  73. CAPS\n",
      "  74. KLK7\n",
      "  75. ADAMTS16\n",
      "  76. PPCDC\n",
      "  77. MERTK\n",
      "  78. ENPP5\n",
      "  79. AMY1A_AMY1B_AMY1C\n",
      "  80. PRG3\n",
      "  81. TNFSF13\n",
      "  82. TXNRD1\n",
      "  83. MLN\n",
      "  84. RGMA\n",
      "  85. MSTN\n",
      "  86. BCAN\n",
      "  87. CCN1\n",
      "  88. CA14\n",
      "  89. CLEC6A\n",
      "  90. TXNDC15\n",
      "  91. NCAN\n",
      "  92. PRSS8\n",
      "  93. SEPTIN8\n",
      "  94. CD80\n",
      "  95. PLA2G15\n",
      "  96. XG\n",
      "  97. TNFSF13B\n",
      "  98. ICAM5\n",
      "  99. SORCS2\n",
      "  100. FABP4\n",
      "  101. NTproBNP\n",
      "  102. SFTPD\n",
      "  103. GIP\n",
      "  104. RSPO3\n",
      "  105. TNFRSF14\n",
      "  106. SUSD2\n",
      "  107. RRM2B\n",
      "  108. CXCL1\n",
      "  109. ANGPTL4\n",
      "  110. VSIG4\n",
      "  111. EFHD1\n",
      "  112. STX6\n",
      "  113. NT5C1A\n",
      "  114. CTSO\n",
      "  115. RSPO1\n",
      "  116. SLC39A5\n",
      "  117. CAPG\n",
      "  118. CEACAM5\n",
      "  119. PTN\n",
      "  120. MSLN\n",
      "  121. DPP10\n",
      "  122. CPM\n",
      "  123. F7\n",
      "  124. PHOSPHO1\n",
      "  125. HNMT\n",
      "  126. FCRL5\n",
      "\n",
      "ğŸ“Š Final feature matrices after RFE:\n",
      "ğŸ‹ï¸  Training: 2963 samples Ã— 126 features\n",
      "ğŸ§ª Validation: 328 samples Ã— 126 features\n",
      "\n",
      "ğŸ“‰ Feature reduction summary:\n",
      "  Original features: 2,131\n",
      "  After PWAS: 200\n",
      "  After RFE: 126\n",
      "  Total reduction: 94.1%\n",
      "âœ… Checkpoint saved: 04_feature_selection\n",
      "   ğŸ“„ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/04_feature_selection.pkl\n",
      "   ğŸ—ƒï¸  DataFrame 'X_train_final': (2963, 126) shape\n",
      "   ğŸ—ƒï¸  DataFrame 'X_val_final': (328, 126) shape\n",
      "ğŸ’¾ Feature selection checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize feature selector\n",
    "feature_selector = FeatureSelector(\n",
    "    random_state=CONFIG['analysis_params']['random_state']\n",
    ")\n",
    "\n",
    "print(\"ğŸ”§ Starting Recursive Feature Elimination...\")\n",
    "\n",
    "# Run RFE with cross-validation\n",
    "rfe_results = feature_selector.run_rfe(\n",
    "    X_train=X_train_selected,\n",
    "    y_train=y_train,\n",
    "    estimator_type='random_forest',\n",
    "    n_features_to_select=CONFIG['feature_params']['rfe_n_features'] if not CONFIG['feature_params']['use_rfe_cv'] else None,\n",
    "    step=CONFIG['feature_params']['rfe_step'],\n",
    "    cv_folds=CONFIG['analysis_params']['cv_folds'],\n",
    "    use_cv=CONFIG['feature_params']['use_rfe_cv']\n",
    ")\n",
    "\n",
    "# Get selected features from RFE\n",
    "selected_features_rfe = feature_selector.get_selected_features()\n",
    "\n",
    "print(f\"\\nğŸ¯ RFE selected {len(selected_features_rfe)} features:\")\n",
    "for i, feature in enumerate(selected_features_rfe, 1):\n",
    "    print(f\"  {i:2d}. {feature}\")\n",
    "\n",
    "# Create final feature matrices\n",
    "X_train_final = feature_selector.transform_features(X_train_selected)\n",
    "X_val_final = feature_selector.transform_features(X_val_selected)\n",
    "\n",
    "print(f\"\\nğŸ“Š Final feature matrices after RFE:\")\n",
    "print(f\"ğŸ‹ï¸  Training: {X_train_final.shape[0]} samples Ã— {X_train_final.shape[1]} features\")\n",
    "print(f\"ğŸ§ª Validation: {X_val_final.shape[0]} samples Ã— {X_val_final.shape[1]} features\")\n",
    "\n",
    "# Print feature reduction summary\n",
    "print(f\"\\nğŸ“‰ Feature reduction summary:\")\n",
    "print(f\"  Original features: {X_train.shape[1]:,}\")\n",
    "print(f\"  After PWAS: {X_train_selected.shape[1]:,}\")\n",
    "print(f\"  After RFE: {X_train_final.shape[1]:,}\")\n",
    "print(f\"  Total reduction: {(1 - X_train_final.shape[1]/X_train.shape[1]):.1%}\")\n",
    "\n",
    "# Save RFE checkpoint\n",
    "rfe_checkpoint = {\n",
    "    'rfe_results': rfe_results,\n",
    "    'selected_features_rfe': selected_features_rfe,\n",
    "    'X_train_final': X_train_final,\n",
    "    'X_val_final': X_val_final\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(\n",
    "    rfe_checkpoint, \n",
    "    '04_feature_selection', \n",
    "    \"Feature selection and RFE completed\"\n",
    ")\n",
    "print(\"ğŸ’¾ Feature selection checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7394ae3",
   "metadata": {},
   "source": [
    "## Section 7: Model Training and Evaluation\n",
    "\n",
    "Train multiple machine learning models using the selected features and evaluate their performance with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a8415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Starting model training and evaluation...\n",
      "ğŸ“‹ Models to compare: ['random_forest', 'logistic_regression', 'xgboost']\n",
      "ğŸ† Comparing 3 models...\n",
      "\n",
      "  ğŸ¤– Training random_forest...\n",
      "ğŸ¤– Training random_forest model...\n",
      "  ğŸ“Š Training: 2963 samples Ã— 126 features\n",
      "  ğŸ§ª Validation: 328 samples\n",
      "  ğŸ”„ Training model...\n",
      "  ğŸ“ˆ Evaluating performance...\n",
      "\n",
      "ğŸ¤– MODEL TRAINING SUMMARY: RANDOM_FOREST\n",
      "  ğŸ“Š Features: 126\n",
      "  ğŸ‘¥ Training samples: 2963\n",
      "  ğŸ§ª Validation samples: 328\n",
      "  ğŸ¯ Training AUC: 1.0000\n",
      "  ğŸ¯ Training Accuracy: 1.0000\n",
      "  ğŸ“Š CV AUC: 0.8255 Â± 0.0525\n",
      "  ğŸ§ª Validation AUC: 0.7785\n",
      "  ğŸ§ª Validation Accuracy: 0.9482\n",
      "  ğŸ² OOB Score: 0.9457\n",
      "\n",
      "  ğŸ¤– Training logistic_regression...\n",
      "ğŸ¤– Training logistic_regression model...\n",
      "  ğŸ“Š Training: 2963 samples Ã— 126 features\n",
      "  ğŸ§ª Validation: 328 samples\n",
      "  ğŸ”„ Training model...\n",
      "  ğŸ“ˆ Evaluating performance...\n",
      "\n",
      "ğŸ¤– MODEL TRAINING SUMMARY: LOGISTIC_REGRESSION\n",
      "  ğŸ“Š Features: 126\n",
      "  ğŸ‘¥ Training samples: 2963\n",
      "  ğŸ§ª Validation samples: 328\n",
      "  ğŸ¯ Training AUC: 0.9168\n",
      "  ğŸ¯ Training Accuracy: 0.8252\n",
      "  ğŸ“Š CV AUC: 0.7969 Â± 0.0295\n",
      "  ğŸ§ª Validation AUC: 0.7344\n",
      "  ğŸ§ª Validation Accuracy: 0.7622\n",
      "\n",
      "  ğŸ¤– Training xgboost...\n",
      "ğŸ¤– Training xgboost model...\n",
      "  ğŸ“Š Training: 2963 samples Ã— 126 features\n",
      "  ğŸ§ª Validation: 328 samples\n",
      "  ğŸ”„ Training model...\n",
      "  ğŸ“ˆ Evaluating performance...\n",
      "\n",
      "ğŸ¤– MODEL TRAINING SUMMARY: XGBOOST\n",
      "  ğŸ“Š Features: 126\n",
      "  ğŸ‘¥ Training samples: 2963\n",
      "  ğŸ§ª Validation samples: 328\n",
      "  ğŸ¯ Training AUC: 1.0000\n",
      "  ğŸ¯ Training Accuracy: 1.0000\n",
      "  ğŸ“Š CV AUC: 0.8465 Â± 0.0384\n",
      "  ğŸ§ª Validation AUC: 0.7594\n",
      "  ğŸ§ª Validation Accuracy: 0.9451\n",
      "\n",
      "ğŸ† MODEL COMPARISON SUMMARY\n",
      "  ================================================================================\n",
      "  Model                Train AUC    CV AUC       Val AUC     \n",
      "  ------------------------------------------------------------\n",
      "  random_forest        1.0000       0.8255       0.7785      \n",
      "  logistic_regression  0.9168       0.7969       0.7344      \n",
      "  xgboost              1.0000       0.8465       0.7594      \n",
      "\n",
      "ğŸ† Model Comparison Results:\n",
      "================================================================================\n",
      "\n",
      "ğŸŒ² RANDOM FOREST\n",
      "  ğŸ¯ Training AUC:   1.0000\n",
      "  ğŸ“Š CV AUC:        0.8255\n",
      "  ğŸ§ª Validation AUC: 0.7785\n",
      "\n",
      "ğŸ“ˆ LOGISTIC REGRESSION\n",
      "  ğŸ¯ Training AUC:   0.9168\n",
      "  ğŸ“Š CV AUC:        0.7969\n",
      "  ğŸ§ª Validation AUC: 0.7344\n",
      "\n",
      "ğŸš€ XGBOOST\n",
      "  ğŸ¯ Training AUC:   1.0000\n",
      "  ğŸ“Š CV AUC:        0.8465\n",
      "  ğŸ§ª Validation AUC: 0.7594\n",
      "\n",
      "ğŸ¥‡ Best model: Xgboost (CV AUC: 0.8465)\n",
      "\n",
      "ğŸ“Š Final validation metrics (Xgboost):\n",
      "  ACCURACY: 0.9451\n",
      "  PRECISION: 0.0000\n",
      "  RECALL: 0.0000\n",
      "  F1_SCORE: 0.0000\n",
      "  AUC: 0.7594\n",
      "\n",
      "Differences from R Pipeline:\n",
      "  ğŸ“Š CV AUC: -0.1427\n",
      "  ğŸ§ª Validation AUC: +0.1073\n",
      "âœ… Python pipeline has better validation performance\n",
      "âœ… Checkpoint saved: 05_model_training\n",
      "   ğŸ“„ Data: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints/05_model_training.pkl\n",
      "ğŸ’¾ Model training checkpoint saved\n"
     ]
    }
   ],
   "source": [
    "# Initialize model trainer\n",
    "model_trainer = ModelTrainer(\n",
    "    random_state=CONFIG['analysis_params']['random_state']\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– Starting model training and evaluation...\")\n",
    "print(f\"ğŸ“‹ Models to compare: {CONFIG['model_params']['model_types']}\")\n",
    "\n",
    "# Compare multiple models (now including XGBoost)\n",
    "model_comparison = model_trainer.compare_models(\n",
    "    X_train=X_train_final,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_final,\n",
    "    y_val=y_val,\n",
    "    model_types=CONFIG['model_params']['model_types'],\n",
    "    cv_folds=CONFIG['analysis_params']['cv_folds']\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ† Model Comparison Results:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model_type = None\n",
    "best_cv_auc = 0\n",
    "\n",
    "for model_type, results in model_comparison.items():\n",
    "    performance = results['performance']\n",
    "    \n",
    "    # Extract key metrics\n",
    "    train_auc = performance.get('train', {}).get('auc', 'N/A')\n",
    "    cv_auc = performance.get('cross_validation', {}).get('auc_mean', 'N/A')\n",
    "    val_auc = performance.get('validation', {}).get('auc', 'N/A')\n",
    "    \n",
    "    # Add emoji for model type\n",
    "    model_emoji = {\n",
    "        'random_forest': 'ğŸŒ²',\n",
    "        'logistic_regression': 'ğŸ“ˆ', \n",
    "        'xgboost': 'ğŸš€'\n",
    "    }.get(model_type, 'ğŸ¤–')\n",
    "    \n",
    "    print(f\"\\n{model_emoji} {model_type.upper().replace('_', ' ')}\")\n",
    "    print(f\"  ğŸ¯ Training AUC:   {train_auc:.4f}\" if isinstance(train_auc, (int, float)) else f\"  ğŸ¯ Training AUC:   {train_auc}\")\n",
    "    print(f\"  ğŸ“Š CV AUC:        {cv_auc:.4f}\" if isinstance(cv_auc, (int, float)) else f\"  ğŸ“Š CV AUC:        {cv_auc}\")\n",
    "    print(f\"  ğŸ§ª Validation AUC: {val_auc:.4f}\" if isinstance(val_auc, (int, float)) else f\"  ğŸ§ª Validation AUC: {val_auc}\")\n",
    "    \n",
    "    # Track best model by CV AUC\n",
    "    if isinstance(cv_auc, (int, float)) and cv_auc > best_cv_auc:\n",
    "        best_cv_auc = cv_auc\n",
    "        best_model_type = model_type\n",
    "\n",
    "print(f\"\\nğŸ¥‡ Best model: {best_model_type.replace('_', ' ').title()} (CV AUC: {best_cv_auc:.4f})\")\n",
    "\n",
    "\n",
    "# Train the best model with hyperparameter tuning if requested\n",
    "if CONFIG['model_params']['hyperparameter_tuning'] and best_model_type:\n",
    "    print(f\"\\nğŸ”§ Training {best_model_type.replace('_', ' ').title()} with hyperparameter tuning...\")\n",
    "    \n",
    "    final_model_results = model_trainer.train_model(\n",
    "        X_train=X_train_final,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_final,\n",
    "        y_val=y_val,\n",
    "        model_type=best_model_type,\n",
    "        hyperparameter_tuning=True,\n",
    "        cv_folds=CONFIG['analysis_params']['cv_folds']\n",
    "    )\n",
    "else:\n",
    "    final_model_results = model_comparison[best_model_type] if best_model_type else None\n",
    "\n",
    "# Generate predictions on validation set\n",
    "if best_model_type and final_model_results:\n",
    "    predictions, probabilities = model_trainer.predict(\n",
    "        X_val_final, \n",
    "        model_type=best_model_type,\n",
    "        return_probabilities=True\n",
    "    )\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    final_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, predictions),\n",
    "        'precision': precision_score(y_val, predictions),\n",
    "        'recall': recall_score(y_val, predictions),\n",
    "        'f1_score': f1_score(y_val, predictions),\n",
    "        'auc': roc_auc_score(y_val, probabilities)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Final validation metrics ({best_model_type.replace('_', ' ').title()}):\")\n",
    "    for metric, value in final_metrics.items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # Calculate and display differences from R pipeline\n",
    "    if isinstance(final_metrics['auc'], (int, float)):\n",
    "        cv_diff = best_cv_auc - 0.9892\n",
    "        val_diff = final_metrics['auc'] - 0.6521\n",
    "        \n",
    "        print(f\"\\nDifferences from R Pipeline:\")\n",
    "        print(f\"  ğŸ“Š CV AUC: {cv_diff:+.4f}\")\n",
    "        print(f\"  ğŸ§ª Validation AUC: {val_diff:+.4f}\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        if cv_diff > 0 and val_diff > 0:\n",
    "            print(\"ğŸ‰ Python pipeline outperforms R pipeline on both metrics!\")\n",
    "        elif val_diff > 0:\n",
    "            print(\"âœ… Python pipeline has better validation performance\")\n",
    "        elif cv_diff > 0:\n",
    "            print(\"âœ… Python pipeline has better cross-validation performance\")\n",
    "        else:\n",
    "            print(\"ğŸ“ Python pipeline has different performance characteristics\")\n",
    "\n",
    "# Save model training checkpoint\n",
    "model_checkpoint = {\n",
    "    'model_comparison': model_comparison,\n",
    "    'best_model_type': best_model_type,\n",
    "    'final_model_results': final_model_results,\n",
    "    'final_metrics': final_metrics if 'final_metrics' in locals() else None,\n",
    "    'predictions': predictions if 'predictions' in locals() else None,\n",
    "    'probabilities': probabilities if 'probabilities' in locals() else None\n",
    "}\n",
    "\n",
    "checkpoint_system.save_checkpoint(\n",
    "    model_checkpoint, \n",
    "    '05_model_training', \n",
    "    f\"Model training and evaluation completed with {len(CONFIG['model_params']['model_types'])} models including XGBoost\"\n",
    ")\n",
    "print(\"ğŸ’¾ Model training checkpoint saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161f8ce",
   "metadata": {},
   "source": [
    "## Section 8: Results Visualization and Summary\n",
    "\n",
    "Generate plots and comprehensive summary to visualize the pipeline results and compare with original R analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea2f6a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Generating comprehensive pipeline results summary...\n",
      "âœ… Checkpoint loaded: 01_data_loading\n",
      "   ğŸ“… Saved: 2025-10-17T20:37:52.076664\n",
      "âœ… Checkpoint loaded: 02_pwas_analysis\n",
      "   ğŸ“… Saved: 2025-10-17T20:38:07.888061\n",
      "âœ… Checkpoint loaded: 03_feature_importance\n",
      "   ğŸ“… Saved: 2025-10-17T20:39:59.376388\n",
      "âœ… Checkpoint loaded: 04_feature_selection\n",
      "   ğŸ“… Saved: 2025-10-17T20:57:57.811384\n",
      "âœ… Checkpoint loaded: 05_model_training\n",
      "   ğŸ“… Saved: 2025-10-17T21:04:57.974893\n",
      "ğŸ“Š Results summary saved to: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports/pipeline_summary.json\n",
      "\n",
      "================================================================================\n",
      "ğŸ§¬ PROTEIN ANALYSIS PIPELINE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ PIPELINE OVERVIEW\n",
      "  âœ… Steps completed: 5\n",
      "  ğŸ•’ Timestamp: 2025-10-17T21:06:15.007180\n",
      "  ğŸ”§ Steps: data_loading, pwas_analysis, feature_importance, feature_selection, model_training\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ˆ PERFORMANCE COMPARISON WITH R PIPELINE\n",
      "================================================================================\n",
      "R Pipeline Results (Reference):\n",
      "  ğŸ§¬ Proteins selected: 200\n",
      "  ğŸ¯ Final features: 8\n",
      "  ğŸ“Š CV AUC: 0.9892\n",
      "  ğŸ§ª Validation AUC: 0.6521\n",
      "\n",
      "Python Pipeline Results (Current):\n",
      "  ğŸ§¬ Proteins selected: 200\n",
      "  ğŸ¯ Final features: 126\n",
      "  ğŸ“Š CV AUC: 0.8465\n",
      "  ğŸ§ª Validation AUC: 0.7594\n",
      "\n",
      "ğŸ§¬ SELECTED FEATURES SUMMARY\n",
      "================================================================================\n",
      "Final selected features (126):\n",
      "   1. ELN                       (importance: 0.0165)\n",
      "   2. TNFRSF10B                 (importance: 0.0121)\n",
      "   3. ADM                       (importance: 0.0196)\n",
      "   4. TREM2                     (importance: 0.0206)\n",
      "   5. IGFBP4                    (importance: 0.0082)\n",
      "   6. CXCL17                    (importance: 0.0103)\n",
      "   7. FUT3_FUT5                 (importance: 0.0081)\n",
      "   8. GFRA1                     (importance: 0.0088)\n",
      "   9. LAMP3                     (importance: 0.0080)\n",
      "  10. PGF                       (importance: 0.0113)\n",
      "  11. LECT2                     (importance: 0.0062)\n",
      "  12. COL9A1                    (importance: 0.0103)\n",
      "  13. EDA2R                     (importance: 0.0088)\n",
      "  14. GDF15                     (importance: 0.0115)\n",
      "  15. CCN3                      (importance: 0.0032)\n",
      "  16. DNER                      (importance: 0.0106)\n",
      "  17. FSTL3                     (importance: 0.0047)\n",
      "  18. PIK3IP1                   (importance: 0.0060)\n",
      "  19. COL18A1                   (importance: 0.0079)\n",
      "  20. CD302                     (importance: 0.0062)\n",
      "  21. CXCL14                    (importance: 0.0094)\n",
      "  22. COL6A3                    (importance: 0.0052)\n",
      "  23. CA6                       (importance: 0.0131)\n",
      "  24. SIGLEC8                   (importance: 0.0107)\n",
      "  25. CD276                     (importance: 0.0075)\n",
      "  26. LGALS9                    (importance: 0.0039)\n",
      "  27. CD300LF                   (importance: 0.0037)\n",
      "  28. GALNT10                   (importance: 0.0082)\n",
      "  29. CXCL9                     (importance: 0.0056)\n",
      "  30. TNFRSF9                   (importance: 0.0047)\n",
      "  31. PRG2                      (importance: 0.0046)\n",
      "  32. EFNA1                     (importance: 0.0057)\n",
      "  33. CD300A                    (importance: 0.0045)\n",
      "  34. CCL23                     (importance: 0.0112)\n",
      "  35. CD99L2                    (importance: 0.0044)\n",
      "  36. PLAUR                     (importance: 0.0033)\n",
      "  37. RBFOX3                    (importance: 0.0044)\n",
      "  38. SCARF2                    (importance: 0.0030)\n",
      "  39. ACTA2                     (importance: 0.0082)\n",
      "  40. LPO                       (importance: 0.0097)\n",
      "  41. CKB                       (importance: 0.0057)\n",
      "  42. SHISA5                    (importance: 0.0051)\n",
      "  43. LILRB4                    (importance: 0.0035)\n",
      "  44. AMBP                      (importance: 0.0043)\n",
      "  45. HLA.E                     (importance: 0.0041)\n",
      "  46. TNFRSF12A                 (importance: 0.0038)\n",
      "  47. IGFBPL1                   (importance: 0.0038)\n",
      "  48. RARRES2                   (importance: 0.0037)\n",
      "  49. ULBP2                     (importance: 0.0036)\n",
      "  50. CDCP1                     (importance: 0.0045)\n",
      "  51. PROK1                     (importance: 0.0084)\n",
      "  52. CLEC4D                    (importance: 0.0045)\n",
      "  53. RNF149                    (importance: 0.0033)\n",
      "  54. CEACAM1                   (importance: 0.0069)\n",
      "  55. WNT9A                     (importance: 0.0049)\n",
      "  56. CCL27                     (importance: 0.0029)\n",
      "  57. AMY2A                     (importance: 0.0092)\n",
      "  58. CHIT1                     (importance: 0.0059)\n",
      "  59. LRRN1                     (importance: 0.0048)\n",
      "  60. FBLN2                     (importance: 0.0047)\n",
      "  61. ADIPOQ                    (importance: 0.0079)\n",
      "  62. CPPED1                    (importance: 0.0066)\n",
      "  63. AMY2B                     (importance: 0.0082)\n",
      "  64. MMP12                     (importance: 0.0059)\n",
      "  65. ADAM9                     (importance: 0.0058)\n",
      "  66. BOC                       (importance: 0.0078)\n",
      "  67. TFF3                      (importance: 0.0048)\n",
      "  68. BGLAP                     (importance: 0.0173)\n",
      "  69. LTA4H                     (importance: 0.0061)\n",
      "  70. HAVCR1                    (importance: 0.0044)\n",
      "  71. PALM2                     (importance: 0.0037)\n",
      "  72. HSPB6                     (importance: 0.0063)\n",
      "  73. CAPS                      (importance: 0.0049)\n",
      "  74. KLK7                      (importance: 0.0083)\n",
      "  75. ADAMTS16                  (importance: 0.0079)\n",
      "  76. PPCDC                     (importance: 0.0034)\n",
      "  77. MERTK                     (importance: 0.0045)\n",
      "  78. ENPP5                     (importance: 0.0050)\n",
      "  79. AMY1A_AMY1B_AMY1C         (importance: 0.0104)\n",
      "  80. PRG3                      (importance: 0.0053)\n",
      "  81. TNFSF13                   (importance: 0.0048)\n",
      "  82. TXNRD1                    (importance: 0.0037)\n",
      "  83. MLN                       (importance: 0.0046)\n",
      "  84. RGMA                      (importance: 0.0097)\n",
      "  85. MSTN                      (importance: 0.0071)\n",
      "  86. BCAN                      (importance: 0.0070)\n",
      "  87. CCN1                      (importance: 0.0061)\n",
      "  88. CA14                      (importance: 0.0076)\n",
      "  89. CLEC6A                    (importance: 0.0038)\n",
      "  90. TXNDC15                   (importance: 0.0041)\n",
      "  91. NCAN                      (importance: 0.0062)\n",
      "  92. PRSS8                     (importance: 0.0039)\n",
      "  93. SEPTIN8                   (importance: 0.0050)\n",
      "  94. CD80                      (importance: 0.0047)\n",
      "  95. PLA2G15                   (importance: 0.0035)\n",
      "  96. XG                        (importance: 0.0037)\n",
      "  97. TNFSF13B                  (importance: 0.0045)\n",
      "  98. ICAM5                     (importance: 0.0036)\n",
      "  99. SORCS2                    (importance: 0.0031)\n",
      "  100. FABP4                     (importance: 0.0049)\n",
      "  101. NTproBNP                  (importance: 0.0045)\n",
      "  102. SFTPD                     (importance: 0.0068)\n",
      "  103. GIP                       (importance: 0.0041)\n",
      "  104. RSPO3                     (importance: 0.0034)\n",
      "  105. TNFRSF14                  (importance: 0.0035)\n",
      "  106. SUSD2                     (importance: 0.0032)\n",
      "  107. RRM2B                     (importance: 0.0037)\n",
      "  108. CXCL1                     (importance: 0.0061)\n",
      "  109. ANGPTL4                   (importance: 0.0032)\n",
      "  110. VSIG4                     (importance: 0.0039)\n",
      "  111. EFHD1                     (importance: 0.0031)\n",
      "  112. STX6                      (importance: 0.0042)\n",
      "  113. NT5C1A                    (importance: 0.0041)\n",
      "  114. CTSO                      (importance: 0.0028)\n",
      "  115. RSPO1                     (importance: 0.0059)\n",
      "  116. SLC39A5                   (importance: 0.0038)\n",
      "  117. CAPG                      (importance: 0.0032)\n",
      "  118. CEACAM5                   (importance: 0.0079)\n",
      "  119. PTN                       (importance: 0.0042)\n",
      "  120. MSLN                      (importance: 0.0042)\n",
      "  121. DPP10                     (importance: 0.0068)\n",
      "  122. CPM                       (importance: 0.0037)\n",
      "  123. F7                        (importance: 0.0028)\n",
      "  124. PHOSPHO1                  (importance: 0.0028)\n",
      "  125. HNMT                      (importance: 0.0034)\n",
      "  126. FCRL5                     (importance: 0.0053)\n",
      "\n",
      "ğŸ’¾ Results saved to:\n",
      "  ğŸ“Š JSON summary: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports/pipeline_summary.json\n",
      "  ğŸ“ Text summary: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/reports/pipeline_summary.txt\n",
      "\n",
      "ğŸ“Š CHECKPOINT SUMMARY - Run ID: unknown\n",
      "============================================================\n",
      "ğŸ“ Checkpoint directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "ğŸ’¾ Total checkpoints: 5\n",
      "\n",
      "ğŸ“‹ Step Details:\n",
      "---------------------------------------------------------------------------\n",
      "ğŸ“¦ 01_data_loading\n",
      "   ğŸ“… Time: 2025-10-17T20:37:52.076664\n",
      "   ğŸ“ Description: Data loading and validation completed\n",
      "   ğŸ’¾ Size: 54.0MB\n",
      "âœ… Checkpoint loaded: 01_data_loading\n",
      "   ğŸ“… Saved: 2025-10-17T20:37:52.076664\n",
      "   ğŸ“Š Data: keys: 6\n",
      "\n",
      "ğŸ“¦ 02_pwas_analysis\n",
      "   ğŸ“… Time: 2025-10-17T20:38:07.888061\n",
      "   ğŸ“ Description: PWAS analysis and protein selection completed\n",
      "   ğŸ’¾ Size: 174.9KB\n",
      "âœ… Checkpoint loaded: 02_pwas_analysis\n",
      "   ğŸ“… Saved: 2025-10-17T20:38:07.888061\n",
      "   ğŸ“Š Data: keys: 4\n",
      "\n",
      "ğŸ“¦ 03_feature_importance\n",
      "   ğŸ“… Time: 2025-10-17T20:39:59.376388\n",
      "   ğŸ“ Description: Feature importance analysis completed\n",
      "   ğŸ’¾ Size: 4.9KB\n",
      "âœ… Checkpoint loaded: 03_feature_importance\n",
      "   ğŸ“… Saved: 2025-10-17T20:39:59.376388\n",
      "   ğŸ“Š Data: keys: 2\n",
      "\n",
      "ğŸ“¦ 04_feature_selection\n",
      "   ğŸ“… Time: 2025-10-17T20:57:57.811384\n",
      "   ğŸ“ Description: Feature selection and RFE completed\n",
      "   ğŸ’¾ Size: 3.5MB\n",
      "âœ… Checkpoint loaded: 04_feature_selection\n",
      "   ğŸ“… Saved: 2025-10-17T20:57:57.811384\n",
      "   ğŸ“Š Data: keys: 4\n",
      "\n",
      "ğŸ“¦ 05_model_training\n",
      "   ğŸ“… Time: 2025-10-17T21:04:57.974893\n",
      "   ğŸ“ Description: Model training and evaluation completed with 3 models including XGBoost\n",
      "   ğŸ’¾ Size: 10.9MB\n",
      "âœ… Checkpoint loaded: 05_model_training\n",
      "   ğŸ“… Saved: 2025-10-17T21:04:57.974893\n",
      "   ğŸ“Š Data: keys: 6\n",
      "\n",
      "\n",
      "ğŸ‰ Pipeline execution completed successfully!\n",
      "â±ï¸  Total execution time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive results summary\n",
    "print(\"ğŸ“Š Generating comprehensive pipeline results summary...\")\n",
    "\n",
    "# Collect all results\n",
    "all_results = {\n",
    "    'data_loading': checkpoint_system.load_checkpoint('01_data_loading') if checkpoint_system.checkpoint_exists('01_data_loading') else None,\n",
    "    'pwas_analysis': checkpoint_system.load_checkpoint('02_pwas_analysis') if checkpoint_system.checkpoint_exists('02_pwas_analysis') else None,\n",
    "    'feature_importance': checkpoint_system.load_checkpoint('03_feature_importance') if checkpoint_system.checkpoint_exists('03_feature_importance') else None,\n",
    "    'feature_selection': checkpoint_system.load_checkpoint('04_feature_selection') if checkpoint_system.checkpoint_exists('04_feature_selection') else None,\n",
    "    'model_training': checkpoint_system.load_checkpoint('05_model_training') if checkpoint_system.checkpoint_exists('05_model_training') else None\n",
    "}\n",
    "\n",
    "# Create results summary\n",
    "summary_path = Path(CONFIG['output_paths']['reports']) / 'pipeline_summary.json'\n",
    "pipeline_summary = create_results_summary(\n",
    "    {k: v for k, v in all_results.items() if v is not None},\n",
    "    save_path=str(summary_path)\n",
    ")\n",
    "\n",
    "# Print formatted summary\n",
    "print_pipeline_summary(pipeline_summary)\n",
    "\n",
    "# Generate text-based visualizations\n",
    "print(f\"\\nğŸ“ˆ PERFORMANCE COMPARISON WITH R PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare with known R results (from the exact_pipeline_reproduction.py)\n",
    "r_pipeline_results = {\n",
    "    'proteins_selected': 200,  # Top 200 proteins selected in R\n",
    "    'final_features': 8,      # Final features after RFE in R  \n",
    "    'cv_auc': 0.9892,        # Cross-validation AUC in R\n",
    "    'val_auc': 0.6521        # Validation AUC in R\n",
    "}\n",
    "\n",
    "print(\"R Pipeline Results (Reference):\")\n",
    "print(f\"  ğŸ§¬ Proteins selected: {r_pipeline_results['proteins_selected']}\")\n",
    "print(f\"  ğŸ¯ Final features: {r_pipeline_results['final_features']}\")\n",
    "print(f\"  ğŸ“Š CV AUC: {r_pipeline_results['cv_auc']:.4f}\")\n",
    "print(f\"  ğŸ§ª Validation AUC: {r_pipeline_results['val_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nPython Pipeline Results (Current):\")\n",
    "print(f\"  ğŸ§¬ Proteins selected: {len(selected_proteins) if 'selected_proteins' in globals() else 'N/A'}\")\n",
    "print(f\"  ğŸ¯ Final features: {len(selected_features_rfe) if 'selected_features_rfe' in globals() else 'N/A'}\")\n",
    "\n",
    "if 'model_checkpoint' in locals() and model_checkpoint['final_model_results']:\n",
    "    final_perf = model_checkpoint['final_model_results']['performance']\n",
    "    cv_auc_python = final_perf.get('cross_validation', {}).get('auc_mean', 'N/A')\n",
    "    val_auc_python = final_perf.get('validation', {}).get('auc', 'N/A')\n",
    "    \n",
    "    print(f\"  ğŸ“Š CV AUC: {cv_auc_python:.4f}\" if isinstance(cv_auc_python, (int, float)) else f\"  ğŸ“Š CV AUC: {cv_auc_python}\")\n",
    "    print(f\"  ğŸ§ª Validation AUC: {val_auc_python:.4f}\" if isinstance(val_auc_python, (int, float)) else f\"  ğŸ§ª Validation AUC: {val_auc_python}\")\n",
    "\n",
    "# Create feature importance visualization (text-based)\n",
    "if 'importance_results' in locals():\n",
    "    print(f\"\\nğŸ§¬ SELECTED FEATURES SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"Final selected features ({len(selected_features_rfe)}):\")\n",
    "    for i, feature in enumerate(selected_features_rfe, 1):\n",
    "        # Find importance score\n",
    "        importance_row = importance_results['feature_importance'][\n",
    "            importance_results['feature_importance']['feature'] == feature\n",
    "        ]\n",
    "        if len(importance_row) > 0:\n",
    "            importance_score = importance_row['importance'].iloc[0]\n",
    "            print(f\"  {i:2d}. {feature:25s} (importance: {importance_score:.4f})\")\n",
    "        else:\n",
    "            print(f\"  {i:2d}. {feature}\")\n",
    "\n",
    "# Save final summary\n",
    "summary_text_path = Path(CONFIG['output_paths']['reports']) / 'pipeline_summary.txt'\n",
    "with open(summary_text_path, 'w') as f:\n",
    "    f.write(\"PROTEIN ANALYSIS PIPELINE SUMMARY\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    f.write(f\"Execution Date: {datetime.now()}\\n\")\n",
    "    f.write(f\"Configuration: {CONFIG}\\n\\n\")\n",
    "    \n",
    "    f.write(\"RESULTS:\\n\")\n",
    "    f.write(f\"- Proteins selected: {len(selected_proteins) if 'selected_proteins' in globals() else 'N/A'}\\n\")\n",
    "    f.write(f\"- Final features: {len(selected_features_rfe) if 'selected_features_rfe' in globals() else 'N/A'}\\n\")\n",
    "    f.write(f\"- Best model: {best_model_type if 'best_model_type' in locals() else 'N/A'}\\n\")\n",
    "    \n",
    "    if 'final_metrics' in locals():\n",
    "        f.write(f\"- Final metrics: {final_metrics}\\n\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Results saved to:\")\n",
    "print(f\"  ğŸ“Š JSON summary: {summary_path}\")\n",
    "print(f\"  ğŸ“ Text summary: {summary_text_path}\")\n",
    "\n",
    "# Display checkpoint system summary\n",
    "checkpoint_system.print_summary()\n",
    "\n",
    "print(f\"\\nğŸ‰ Pipeline execution completed successfully!\")\n",
    "print(f\"â±ï¸  Total execution time: {checkpoint_system.get_total_execution_time():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0fd12",
   "metadata": {},
   "source": [
    "## Section 9: Checkpoint Management and Recovery\n",
    "\n",
    "Demonstrate checkpoint loading functionality, resume training from saved states, and validate checkpoint integrity across pipeline runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4fc50fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Checkpoint Management and Recovery Demo\n",
      "==================================================\n",
      "\n",
      "ğŸ“‹ Available checkpoints (5):\n",
      "  âœ… 01_data_loading: 2025-10-17T20:37:52.076664\n",
      "  âœ… 02_pwas_analysis: 2025-10-17T20:38:07.888061\n",
      "  âœ… 03_feature_importance: 2025-10-17T20:39:59.376388\n",
      "  âœ… 04_feature_selection: 2025-10-17T20:57:57.811384\n",
      "  âœ… 05_model_training: 2025-10-17T21:04:57.974893\n",
      "\n",
      "ğŸ”„ Demonstrating checkpoint recovery...\n",
      "\n",
      "ğŸ“¥ Loading data checkpoint...\n",
      "âœ… Checkpoint loaded: 01_data_loading\n",
      "   ğŸ“… Saved: 2025-10-17T20:37:52.076664\n",
      "  âœ… Recovered data shapes:\n",
      "    Training: (2963, 2131)\n",
      "    Validation: (328, 2131)\n",
      "    Target distribution: {0: 2803, 1: 160}\n",
      "\n",
      "ğŸ“¥ Loading PWAS checkpoint...\n",
      "âœ… Checkpoint loaded: 02_pwas_analysis\n",
      "   ğŸ“… Saved: 2025-10-17T20:38:07.888061\n",
      "  âœ… Recovered PWAS results:\n",
      "    Selected proteins: 200\n",
      "    Feature matrix shape: (2963, 200)\n",
      "\n",
      "ğŸ“¥ Loading feature selection checkpoint...\n",
      "âœ… Checkpoint loaded: 04_feature_selection\n",
      "   ğŸ“… Saved: 2025-10-17T20:57:57.811384\n",
      "  âœ… Recovered RFE results:\n",
      "    Final features: 126\n",
      "    Final matrix shape: (2963, 126)\n",
      "\n",
      "ğŸ” Checkpoint integrity validation:\n",
      "âœ… Checkpoint loaded: 01_data_loading\n",
      "   ğŸ“… Saved: 2025-10-17T20:37:52.076664\n",
      "  âœ… 01_data_loading: Valid\n",
      "    - File size: 55271.0 KB\n",
      "âœ… Checkpoint loaded: 02_pwas_analysis\n",
      "   ğŸ“… Saved: 2025-10-17T20:38:07.888061\n",
      "  âœ… 02_pwas_analysis: Valid\n",
      "    - File size: 174.9 KB\n",
      "âœ… Checkpoint loaded: 03_feature_importance\n",
      "   ğŸ“… Saved: 2025-10-17T20:39:59.376388\n",
      "  âœ… 03_feature_importance: Valid\n",
      "    - File size: 4.9 KB\n",
      "âœ… Checkpoint loaded: 04_feature_selection\n",
      "   ğŸ“… Saved: 2025-10-17T20:57:57.811384\n",
      "  âœ… 04_feature_selection: Valid\n",
      "    - File size: 3545.5 KB\n",
      "âœ… Checkpoint loaded: 05_model_training\n",
      "   ğŸ“… Saved: 2025-10-17T21:04:57.974893\n",
      "  âœ… 05_model_training: Valid\n",
      "    - File size: 11172.6 KB\n",
      "\n",
      "ğŸ”„ Pipeline restart demonstration:\n",
      "To restart the pipeline from any checkpoint, use:\n",
      "\n",
      "```python\n",
      "# Load checkpoint\n",
      "checkpoint_data = checkpoint_system.load_checkpoint('02_pwas_analysis')\n",
      "\n",
      "# Resume from that point\n",
      "X_train_selected = checkpoint_data['X_train_selected']\n",
      "selected_proteins = checkpoint_data['selected_proteins']\n",
      "\n",
      "# Continue with feature importance analysis...\n",
      "importance_analyzer = FeatureImportanceAnalyzer()\n",
      "# ... rest of pipeline\n",
      "```\n",
      "\n",
      "ğŸ“œ Checkpoint recovery script created: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoint_recovery.py\n",
      "\n",
      "ğŸ“Š Final Checkpoint System Summary:\n",
      "\n",
      "ğŸ“Š CHECKPOINT SUMMARY - Run ID: unknown\n",
      "============================================================\n",
      "ğŸ“ Checkpoint directory: /home/itg/oleg.vlasovets/projects/protein-benchmark/results/pipeline_run/checkpoints\n",
      "ğŸ’¾ Total checkpoints: 5\n",
      "\n",
      "ğŸ“‹ Step Details:\n",
      "---------------------------------------------------------------------------\n",
      "ğŸ“¦ 01_data_loading\n",
      "   ğŸ“… Time: 2025-10-17T20:37:52.076664\n",
      "   ğŸ“ Description: Data loading and validation completed\n",
      "   ğŸ’¾ Size: 54.0MB\n",
      "âœ… Checkpoint loaded: 01_data_loading\n",
      "   ğŸ“… Saved: 2025-10-17T20:37:52.076664\n",
      "   ğŸ“Š Data: keys: 6\n",
      "\n",
      "ğŸ“¦ 02_pwas_analysis\n",
      "   ğŸ“… Time: 2025-10-17T20:38:07.888061\n",
      "   ğŸ“ Description: PWAS analysis and protein selection completed\n",
      "   ğŸ’¾ Size: 174.9KB\n",
      "âœ… Checkpoint loaded: 02_pwas_analysis\n",
      "   ğŸ“… Saved: 2025-10-17T20:38:07.888061\n",
      "   ğŸ“Š Data: keys: 4\n",
      "\n",
      "ğŸ“¦ 03_feature_importance\n",
      "   ğŸ“… Time: 2025-10-17T20:39:59.376388\n",
      "   ğŸ“ Description: Feature importance analysis completed\n",
      "   ğŸ’¾ Size: 4.9KB\n",
      "âœ… Checkpoint loaded: 03_feature_importance\n",
      "   ğŸ“… Saved: 2025-10-17T20:39:59.376388\n",
      "   ğŸ“Š Data: keys: 2\n",
      "\n",
      "ğŸ“¦ 04_feature_selection\n",
      "   ğŸ“… Time: 2025-10-17T20:57:57.811384\n",
      "   ğŸ“ Description: Feature selection and RFE completed\n",
      "   ğŸ’¾ Size: 3.5MB\n",
      "âœ… Checkpoint loaded: 04_feature_selection\n",
      "   ğŸ“… Saved: 2025-10-17T20:57:57.811384\n",
      "   ğŸ“Š Data: keys: 4\n",
      "\n",
      "ğŸ“¦ 05_model_training\n",
      "   ğŸ“… Time: 2025-10-17T21:04:57.974893\n",
      "   ğŸ“ Description: Model training and evaluation completed with 3 models including XGBoost\n",
      "   ğŸ’¾ Size: 10.9MB\n",
      "âœ… Checkpoint loaded: 05_model_training\n",
      "   ğŸ“… Saved: 2025-10-17T21:04:57.974893\n",
      "   ğŸ“Š Data: keys: 6\n",
      "\n",
      "\n",
      "ğŸ¯ Checkpoint management demonstration completed!\n",
      "ğŸ’¡ All checkpoints are ready for pipeline recovery and resumption.\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ’¾ Checkpoint Management and Recovery Demo\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# List all available checkpoints\n",
    "available_checkpoints = checkpoint_system.list_checkpoints()\n",
    "print(f\"\\nğŸ“‹ Available checkpoints ({len(available_checkpoints)}):\")\n",
    "for checkpoint in available_checkpoints:\n",
    "    step_name = checkpoint['step_name']\n",
    "    metadata = checkpoint_system.get_checkpoint_info(step_name)\n",
    "    print(f\"  âœ… {step_name}: {metadata.get('timestamp', 'Unknown time')}\")\n",
    "\n",
    "# Demonstrate checkpoint loading\n",
    "print(f\"\\nğŸ”„ Demonstrating checkpoint recovery...\")\n",
    "\n",
    "# Example: Load data loading checkpoint\n",
    "if checkpoint_system.checkpoint_exists('01_data_loading'):\n",
    "    print(f\"\\nğŸ“¥ Loading data checkpoint...\")\n",
    "    data_checkpoint = checkpoint_system.load_checkpoint('01_data_loading')\n",
    "    print(f\"  âœ… Recovered data shapes:\")\n",
    "    print(f\"    Training: {data_checkpoint['X_train'].shape}\")\n",
    "    print(f\"    Validation: {data_checkpoint['X_val'].shape}\")\n",
    "    print(f\"    Target distribution: {data_checkpoint['y_train'].value_counts().to_dict()}\")\n",
    "\n",
    "# Example: Load PWAS results\n",
    "if checkpoint_system.checkpoint_exists('02_pwas_analysis'):\n",
    "    print(f\"\\nğŸ“¥ Loading PWAS checkpoint...\")\n",
    "    pwas_checkpoint_loaded = checkpoint_system.load_checkpoint('02_pwas_analysis')\n",
    "    print(f\"  âœ… Recovered PWAS results:\")\n",
    "    print(f\"    Selected proteins: {len(pwas_checkpoint_loaded['selected_proteins'])}\")\n",
    "    print(f\"    Feature matrix shape: {pwas_checkpoint_loaded['X_train_selected'].shape}\")\n",
    "\n",
    "# Example: Load feature selection results  \n",
    "if checkpoint_system.checkpoint_exists('04_feature_selection'):\n",
    "    print(f\"\\nğŸ“¥ Loading feature selection checkpoint...\")\n",
    "    rfe_checkpoint_loaded = checkpoint_system.load_checkpoint('04_feature_selection')\n",
    "    print(f\"  âœ… Recovered RFE results:\")\n",
    "    print(f\"    Final features: {len(rfe_checkpoint_loaded['selected_features_rfe'])}\")\n",
    "    print(f\"    Final matrix shape: {rfe_checkpoint_loaded['X_train_final'].shape}\")\n",
    "\n",
    "# Validate checkpoint integrity\n",
    "print(f\"\\nğŸ” Checkpoint integrity validation:\")\n",
    "\n",
    "integrity_results = {}\n",
    "for checkpoint in available_checkpoints:\n",
    "    step_name = checkpoint['step_name']\n",
    "    try:\n",
    "        checkpoint_data = checkpoint_system.load_checkpoint(step_name)\n",
    "        metadata = checkpoint_system.get_checkpoint_info(step_name)\n",
    "        # Basic validation checks\n",
    "        is_valid = True\n",
    "        validation_messages = []\n",
    "        if checkpoint_data is None:\n",
    "            is_valid = False\n",
    "            validation_messages.append(\"Checkpoint data is None\")\n",
    "        if not metadata:\n",
    "            validation_messages.append(\"No metadata found\")\n",
    "        checkpoint_path = Path(checkpoint['file_path'])\n",
    "        if checkpoint_path.exists():\n",
    "            file_size = checkpoint_path.stat().st_size\n",
    "            if file_size == 0:\n",
    "                is_valid = False\n",
    "                validation_messages.append(\"Checkpoint file is empty\")\n",
    "            else:\n",
    "                validation_messages.append(f\"File size: {file_size/1024:.1f} KB\")\n",
    "        integrity_results[step_name] = {\n",
    "            'valid': is_valid,\n",
    "            'messages': validation_messages\n",
    "        }\n",
    "        status_icon = \"âœ…\" if is_valid else \"âŒ\"\n",
    "        print(f\"  {status_icon} {step_name}: {'Valid' if is_valid else 'Invalid'}\")\n",
    "        for msg in validation_messages:\n",
    "            print(f\"    - {msg}\")\n",
    "    except Exception as e:\n",
    "        integrity_results[step_name] = {\n",
    "            'valid': False,\n",
    "            'messages': [f\"Error loading: {str(e)}\"]\n",
    "        }\n",
    "        print(f\"  âŒ {step_name}: Error - {str(e)}\")\n",
    "\n",
    "# Demonstrate pipeline restart from checkpoint\n",
    "print(f\"\\nğŸ”„ Pipeline restart demonstration:\")\n",
    "print(f\"To restart the pipeline from any checkpoint, use:\")\n",
    "print(f\"\")\n",
    "print(f\"```python\")\n",
    "print(f\"# Load checkpoint\")\n",
    "print(f\"checkpoint_data = checkpoint_system.load_checkpoint('02_pwas_analysis')\")\n",
    "print(f\"\")\n",
    "print(f\"# Resume from that point\")\n",
    "print(f\"X_train_selected = checkpoint_data['X_train_selected']\")\n",
    "print(f\"selected_proteins = checkpoint_data['selected_proteins']\")\n",
    "print(f\"\")\n",
    "print(f\"# Continue with feature importance analysis...\")\n",
    "print(f\"importance_analyzer = FeatureImportanceAnalyzer()\")\n",
    "print(f\"# ... rest of pipeline\")\n",
    "print(f\"```\")\n",
    "\n",
    "# Create checkpoint recovery script\n",
    "recovery_script_path = Path(CONFIG['output_paths']['base_dir']) / 'checkpoint_recovery.py'\n",
    "recovery_script = f'''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Checkpoint Recovery Script\n",
    "==========================\n",
    "\n",
    "This script demonstrates how to recover and resume the pipeline from any checkpoint.\n",
    "Generated automatically by the pipeline orchestrator.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/itg/oleg.vlasovets/projects/protein-benchmark')\n",
    "\n",
    "from pipeline import CheckpointSystem\n",
    "\n",
    "# Initialize checkpoint system\n",
    "checkpoint_system = CheckpointSystem('{CONFIG['output_paths']['checkpoints']}')\n",
    "\n",
    "# List available checkpoints\n",
    "print(\"Available checkpoints:\")\n",
    "for checkpoint in checkpoint_system.list_checkpoints():\n",
    "    step_name = checkpoint['step_name']\n",
    "    metadata = checkpoint_system.get_checkpoint_info(step_name)\n",
    "    print(f\"  - {{step_name}}: {{metadata.get('timestamp', 'Unknown')}}\")\n",
    "\n",
    "# Example: Resume from PWAS analysis\n",
    "if checkpoint_system.checkpoint_exists('02_pwas_analysis'):\n",
    "    print(\"\\\\nResuming from PWAS analysis checkpoint...\")\n",
    "    pwas_data = checkpoint_system.load_checkpoint('02_pwas_analysis')\n",
    "    # Extract recovered data\n",
    "    selected_proteins = pwas_data['selected_proteins']\n",
    "    X_train_selected = pwas_data['X_train_selected']\n",
    "    print(f\"Recovered {{len(selected_proteins)}} selected proteins\")\n",
    "    print(f\"Feature matrix shape: {{X_train_selected.shape}}\")\n",
    "    # Continue with next step...\n",
    "    # (Add your continuation logic here)\n",
    "else:\n",
    "    print(\"PWAS checkpoint not found. Run the full pipeline first.\")\n",
    "'''\n",
    "\n",
    "with open(recovery_script_path, 'w') as f:\n",
    "    f.write(recovery_script)\n",
    "\n",
    "print(f\"\\nğŸ“œ Checkpoint recovery script created: {recovery_script_path}\")\n",
    "\n",
    "# Final checkpoint summary\n",
    "print(f\"\\nğŸ“Š Final Checkpoint System Summary:\")\n",
    "checkpoint_system.print_summary()\n",
    "\n",
    "print(f\"\\nğŸ¯ Checkpoint management demonstration completed!\")\n",
    "print(f\"ğŸ’¡ All checkpoints are ready for pipeline recovery and resumption.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fede2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook successfully demonstrates the complete protein analysis pipeline, reproducing the R methodology with modular Python components. The pipeline includes:\n",
    "\n",
    "### âœ… **Completed Steps:**\n",
    "1. **Data Loading**: Loaded protein expression and phenotype data with validation\n",
    "2. **PWAS Analysis**: Performed protein-wide association study with R fallback strategy\n",
    "3. **Feature Importance**: Ranked proteins using Random Forest importance\n",
    "4. **Feature Selection**: Applied RFE to select optimal feature set\n",
    "5. **Model Training**: Trained and compared multiple ML models\n",
    "6. **Results Analysis**: Generated comprehensive performance metrics\n",
    "7. **Checkpoint System**: Implemented robust checkpoint management for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99959e21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
